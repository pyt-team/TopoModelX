{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Hypergraph Neural Network\n",
    "\n",
    "In this notebook, we will create and train a two-step message passing network in the hypergraph domain. We will use a benchmark dataset, MUTAG (from the TUDataset), to train the model to perform binary classification at the level of the h. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.222779223Z",
     "start_time": "2023-06-01T16:14:49.575421023Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.222779223Z",
     "start_time": "2023-06-01T16:14:49.575421023Z"
    }
   },
   "outputs": [],
   "source": [
    "from toponetx import SimplicialComplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.222779223Z",
     "start_time": "2023-06-01T16:14:49.575421023Z"
    }
   },
   "outputs": [],
   "source": [
    "import toponetx.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.222779223Z",
     "start_time": "2023-06-01T16:14:49.575421023Z"
    }
   },
   "outputs": [],
   "source": [
    "from topomodelx.nn.hypergraph.template_layer import TemplateLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:51.959770754Z",
     "start_time": "2023-06-01T16:14:51.956096841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, shrec 16, a benchmark dataset for 3D mesh classification. We then lift each graph into our domain of choice, a hypergraph.\n",
    "\n",
    "We will also retrieve:\n",
    "- input signal on the edges for each of these hypergraphs, as that will be what we feed the model in input\n",
    "- the label associated to the hypergraph\n",
    "\n",
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on each simplicial complex. In the case of this architecture, we need the boundary matrix (or incidence matrix) $B_1$ with shape $n_\\text{nodes} \\times n_\\text{edges}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:53.022151550Z",
     "start_time": "2023-06-01T16:14:52.949636599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "done!\n",
      "(252, 6)\n",
      "(252, 6)\n",
      "(252, 6)\n",
      "(750, 10)\n",
      "(750, 10)\n",
      "(750, 10)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "# Convert NpzFile objects to NumPy arrays\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]\n",
    "\n",
    "hg_list = []\n",
    "hg_list_test = []\n",
    "incidence_1_list = []\n",
    "\n",
    "for simplex in simplexes:\n",
    "    incidence_1 = simplex.incidence_matrix(rank=1, signed=False)\n",
    "    incidence_1 = torch.from_numpy(incidence_1.todense()).to_sparse()\n",
    "    incidence_1_list.append(incidence_1)\n",
    "    hg = simplex.to_hypergraph()\n",
    "    hg_list.append(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th is an hypergraph with incidence matrix of shape torch.Size([252, 750]).\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th is an hypergraph with incidence matrix of shape {incidence_1_list[i_complex].shape}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the TemplateLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:55.343005145Z",
     "start_time": "2023-06-01T16:14:55.339481459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5-th hypergraph has the following node features: (252, 6)\n",
      "The 5-th hypergraph has the following edge features: (750, 10)\n"
     ]
    }
   ],
   "source": [
    "channels_edge = x_1s[0].shape[1]\n",
    "channels_node = x_0s[0].shape[1]\n",
    "\n",
    "i_hg = 5\n",
    "print(f\"The {i_hg}-th hypergraph has the following node features: {x_0s[i_hg].shape}\")\n",
    "print(f\"The {i_hg}-th hypergraph has the following edge features: {x_1s[i_hg].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:56.033274119Z",
     "start_time": "2023-06-01T16:14:56.029056913Z"
    }
   },
   "outputs": [],
   "source": [
    "class TemplateNN(torch.nn.Module):\n",
    "    \"\"\"Neural network implementation of Template for hypergraph classification.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    channels_edge : int\n",
    "        Dimension of edge features\n",
    "    channels_node : int\n",
    "        Dimension of node features\n",
    "    n_layer : 2\n",
    "        Amount of message passing layers.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels_edge, channels_node, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                TemplateLayer(\n",
    "                    in_channels=channels_edge,\n",
    "                    intermediate_channels=channels_node,\n",
    "                    out_channels=channels_edge,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.linear = torch.nn.Linear(channels_edge, 1)\n",
    "\n",
    "    def forward(self, x_1, incidence_1):\n",
    "        \"\"\"Forward computation through layers, then linear layer, then global max pooling.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_1 : tensor\n",
    "            shape = [n_edges, channels_edge]\n",
    "            Edge features.\n",
    "\n",
    "        incidence_1 : tensor\n",
    "            shape = [n_nodes, n_edges]\n",
    "            Boundary matrix of rank 1.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_1 = layer(x_1, incidence_1)\n",
    "        pooled_x = torch.max(x_1, dim=0)[0]\n",
    "        return torch.sigmoid(self.linear(pooled_x))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, the loss, and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:58.153514385Z",
     "start_time": "2023-06-01T16:14:57.243596119Z"
    }
   },
   "outputs": [],
   "source": [
    "model = TemplateNN(channels_edge, channels_node, n_layers=2)\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:14:59.046068930Z",
     "start_time": "2023-06-01T16:14:59.037648626Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "incidence_1_train, incidence_1_test = train_test_split(\n",
    "    incidence_1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell performs the training, looping over the network for a low amount of epochs. We keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T16:15:01.683216142Z",
     "start_time": "2023-06-01T16:15:00.727075750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 2 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 3 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 4 loss: 274.6125\n",
      "Test_loss: 529.0000\n",
      "Epoch: 5 loss: 274.6125\n",
      "Test_loss: 529.0000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 5\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_1, incidence_1, y in zip(x_1_train, incidence_1_train, y_train):\n",
    "        x_1 = torch.tensor(x_1)\n",
    "        x_1, incidence_1, y = (\n",
    "            x_1.float().to(device),\n",
    "            incidence_1.float().to(device),\n",
    "            torch.tensor(y, dtype=torch.float).to(device),\n",
    "        )\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_1, incidence_1)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        # print(loss)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_1, incidence_1, y in zip(x_1_test, incidence_1_test, y_test):\n",
    "                x_1 = torch.tensor(x_1)\n",
    "                x_1, incidence_1, y = (\n",
    "                    x_1.float().to(device),\n",
    "                    incidence_1.float().to(device),\n",
    "                    torch.tensor(y, dtype=torch.float).to(device),\n",
    "                )\n",
    "                y_hat = model(x_1, incidence_1)\n",
    "                loss = loss_fn(y_hat, y)\n",
    "\n",
    "            print(f\"Test_loss: {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
