{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a hypergraph neural network using UniGCNII layers\n",
    "\n",
    "This tutorial consists of three main steps:\n",
    "1. Loading the CiCitationCora dataset and lifting it to the hypergraph domain.\n",
    "2. Defining a hypergraph neural network (HGNN) which utlilizes the UniGCNII layer, and\n",
    "3. Training the obtained neural network on the training data and evaluating it on test data.\n",
    "\n",
    "First, we import the neccessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from topomodelx.nn.hypergraph.unigcnii_layer import UniGCNIILayer\n",
    "from topomodelx.nn.hypergraph.unigcnii import UniGCNII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available, we want to make use of them, otherwise the model is run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We are using the Cora co-citation dataset. Here, the nodes represent documents and the edges in the graph represent documents which are co-cited. It is possible to compute this graph from the citation network directly. However, this is computationally very expensive. Instead, we load the dataset directly as it is available to download.\n",
    "\n",
    "The task here is to classify each node and assign one of 7 possible classes to it. The dataset is a standard benchmark used in HGNN literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-21 23:36:32--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle [following]\n",
      "--2023-09-21 23:36:32--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/features.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 404937 (395K) [application/octet-stream]\n",
      "Saving to: ‘features.pickle.1’\n",
      "\n",
      "features.pickle.1   100%[===================>] 395.45K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-09-21 23:36:32 (31.3 MB/s) - ‘features.pickle.1’ saved [404937/404937]\n",
      "\n",
      "--2023-09-21 23:36:33--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle [following]\n",
      "--2023-09-21 23:36:33--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/hypergraph.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 101905 (100K) [application/octet-stream]\n",
      "Saving to: ‘hypergraph.pickle.1’\n",
      "\n",
      "hypergraph.pickle.1 100%[===================>]  99.52K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2023-09-21 23:36:33 (23.1 MB/s) - ‘hypergraph.pickle.1’ saved [101905/101905]\n",
      "\n",
      "--2023-09-21 23:36:33--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle [following]\n",
      "--2023-09-21 23:36:34--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/labels.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5436 (5.3K) [application/octet-stream]\n",
      "Saving to: ‘labels.pickle.1’\n",
      "\n",
      "labels.pickle.1     100%[===================>]   5.31K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-09-21 23:36:34 (59.1 MB/s) - ‘labels.pickle.1’ saved [5436/5436]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/features.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/hypergraph.pickle\n",
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/labels.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-21 23:36:34--  https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle\n",
      "Resolving github.com (github.com)... 192.30.255.113\n",
      "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle [following]\n",
      "--2023-09-21 23:36:35--  https://raw.githubusercontent.com/malllabiisc/HyperGCN/master/data/cocitation/cora/splits/1.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51582 (50K) [application/octet-stream]\n",
      "Saving to: ‘1.pickle.1’\n",
      "\n",
      "1.pickle.1          100%[===================>]  50.37K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2023-09-21 23:36:35 (12.9 MB/s) - ‘1.pickle.1’ saved [51582/51582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/malllabiisc/HyperGCN/raw/master/data/cocitation/cora/splits/1.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_998306/2369537045.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  features = pickle.load(handle).todense()\n"
     ]
    }
   ],
   "source": [
    "with open(\"features.pickle\", \"rb\") as handle:\n",
    "    features = pickle.load(handle).todense()\n",
    "\n",
    "with open(\"hypergraph.pickle\", \"rb\") as handle:\n",
    "    hypergraph = pickle.load(handle)\n",
    "\n",
    "with open(\"labels.pickle\", \"rb\") as handle:\n",
    "    labels = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the input and output features to pytorch\n",
    "x_0 = sp.csr_matrix(np.array(features), dtype=np.float32)\n",
    "x_0 = torch.FloatTensor(np.array(x_0.todense()))\n",
    "x_0 = x_0.to(device)\n",
    "\n",
    "y = torch.LongTensor(np.array(labels))\n",
    "y = y.to(device)\n",
    "\n",
    "# construct the incidence matrix\n",
    "h = np.zeros((x_0.shape[0], len(hypergraph)))\n",
    "\n",
    "for num, nodes in enumerate(hypergraph.values()):\n",
    "    h[list(nodes), num] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add self-loops to the dataset i.e. for every node $v$, we add a hyper-edge only containing that specific node $e = \\{ v \\}$. This is the standard format expected by the GCNII layers and transform the matrix into a sparse pytorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_998306/2226475299.py:6: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  incidence = torch.Tensor(incidence).to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "# add self loops\n",
    "h2 = np.eye(x_0.shape[0])\n",
    "incidence = np.hstack((h, h2))\n",
    "\n",
    "# transform to pytorch\n",
    "incidence = torch.Tensor(incidence).to_sparse_csr()\n",
    "incidence = incidence.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the predefine split in test and train data before we start constructing the HGNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train-test split given by the dataset\n",
    "with open(\"1.pickle\", \"rb\") as H:\n",
    "    splits = pickle.load(H)\n",
    "    train, test = splits[\"train\"], splits[\"test\"]\n",
    "\n",
    "train_idx = torch.LongTensor(train).to(device)\n",
    "test_idx = torch.LongTensor(test).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniGCNIIModel(torch.nn.Module):\n",
    "    \"\"\"Hypergraph neural network utilizing the UniGCNII layer for node-level classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes: int, default=2\n",
    "        Number of classes used for node classification.\n",
    "    in_features: int, default=1\n",
    "        Number of input features on the nodes.\n",
    "    n_layers: int, default=2\n",
    "        Number of UniGCNII message passing layers.\n",
    "    alpha: float, default=0.5\n",
    "        Parameter of the UniGCNII layer.\n",
    "    beta: float, default=0.5\n",
    "        Parameter of the UniGCNII layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=2, in_features=1, num_layers=2, alpha=0.5, beta=0.5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        self.num_features = in_features\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(\n",
    "                UniGCNIILayer(in_channels=in_features, alpha=alpha, beta=beta)\n",
    "            )\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.linear = torch.nn.Linear(self.num_features, self.num_classes)\n",
    "\n",
    "    def forward(self, x_0, incidence_1):\n",
    "        \"\"\"forward pass through the model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_0 : torch.Tensor, shape = [num_nodes, in_channels]\n",
    "            Input features of the nodes of the hypergraph.\n",
    "        incidence_1 : torch.Tensor, shape = [num_nodes, num_edges]\n",
    "            Incidence matrix of the hypergraph.\n",
    "            It is expected that the incidence matrix contains self-loops for all nodes.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_hat : torch.Tensor, shape = [num_nodes, num_classes]\n",
    "            Contains the logits for classification for every node.\n",
    "        \"\"\"\n",
    "        # Copy the original features to use as skip connections\n",
    "        x_0_skip = x_0.clone()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_0 = layer(x_0, incidence_1, x_0_skip)\n",
    "\n",
    "        # linear layer for node classification output\n",
    "        # softmax ommited for use of cross-entropy loss\n",
    "        return self.linear(x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the neural network\n",
    "\n",
    "First, we specify the hyperparameters of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "test_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate the corresponding model, optimizer, and loss function with corresponding sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = x_0.shape[1]\n",
    "classes = 7  # current problem has 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UniGCNII(num_classes=classes, in_features=channels, num_layers=3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train the created model and evaluate the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 \t Train accuracy: 0.75 \t Test accuracy: 0.5023364424705505\n",
      "Epoch: 10 \t Train accuracy: 0.75 \t Test accuracy: 0.5440031290054321\n",
      "Epoch: 15 \t Train accuracy: 0.9071428775787354 \t Test accuracy: 0.5502336621284485\n",
      "Epoch: 20 \t Train accuracy: 0.9357143044471741 \t Test accuracy: 0.6035825610160828\n",
      "Epoch: 25 \t Train accuracy: 0.9857142567634583 \t Test accuracy: 0.5576323866844177\n",
      "Epoch: 30 \t Train accuracy: 0.9785714149475098 \t Test accuracy: 0.5362149477005005\n",
      "Epoch: 35 \t Train accuracy: 0.9928571581840515 \t Test accuracy: 0.5362149477005005\n",
      "Epoch: 40 \t Train accuracy: 0.9785714149475098 \t Test accuracy: 0.5221962332725525\n",
      "Epoch: 45 \t Train accuracy: 1.0 \t Test accuracy: 0.5697040557861328\n",
      "Epoch: 50 \t Train accuracy: 0.9928571581840515 \t Test accuracy: 0.5112928152084351\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    y_hat = model(x_0, incidence)\n",
    "    loss = loss_fn(y_hat[train_idx], y[train_idx])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Evaluate performance on the validation data\n",
    "    if (epoch + 1) % test_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x_0, incidence)\n",
    "            y_pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "            train_acc = (y_pred[train_idx] == y[train_idx]).float().mean()\n",
    "            test_acc = (y_pred[test_idx] == y[test_idx]).float().mean()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1} \\t Train accuracy: {train_acc} \\t Test accuracy: {test_acc}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('topox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6db82bc84658dc379dad2324c4569572404d1e9acb031924959aac21ff559da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
