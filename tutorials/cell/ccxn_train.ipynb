{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Convolutional Cell Complex Network (CCXN)\n",
    "\n",
    "We create and train a simplified version of the CCXN originally proposed in [Hajij et. al : Cell Complex Neural Networks (2020)](https://arxiv.org/pdf/2010.00743.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "1. A convolution from nodes to nodes using an adjacency message passing scheme (AMPS):\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(0 \\rightarrow 1 \\rightarrow 0)} = M_{\\mathcal{L}_\\uparrow}^t(h_x^{t,(0)}, h_y^{t,(0)}, \\Theta^{t,(y \\rightarrow x)})$ \n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1 \\rightarrow 0)} = AGG_{y \\in \\mathcal{L}_\\uparrow(x)}(m_{y \\rightarrow \\{z\\} \\rightarrow x}^{0 \\rightarrow 1 \\rightarrow 0})$ \n",
    "\n",
    "游릴 $\\quad m_x^{(0)} = m_x^{(0 \\rightarrow 1 \\rightarrow 0)}$ \n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = U^{t}(h_x^{t,(0)}, m_x^{(0)})$\n",
    "\n",
    "2. A convolution from edges to faces using a cohomology message passing scheme:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = M^t_{\\mathcal{C}}(h_{x}^{t,(r)}, h_y^{t,(r')}, x, y)$ \n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)}  = AGG_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릱 $\\quad h_{x}^{t+1,(r)} = U^{t,(r)}(h_{x}^{t,(r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031).\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on a small version of [shrec16](http://shapenet.cs.stanford.edu/shrec16/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:06:36.009880829Z",
     "start_time": "2023-05-31T09:06:34.285257706Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from toponetx import CellComplex\n",
    "import toponetx.datasets as datasets\n",
    "\n",
    "from topomodelx.nn.cell.ccxn_layer import CCXNLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:53.006542411Z",
     "start_time": "2023-05-31T09:13:52.963074076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, shrec16, a benchmark dataset for 3D mesh classification. We then lift each graph into our domain of choice, a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a scalar classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "simplexes = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift into cell complex domain and define neighborhood structures ##\n",
    "\n",
    "We lift each simplicial complex into a cell complex.\n",
    "\n",
    "Then, we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on each cell complex. In the case of this architecture, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_list = []\n",
    "incidence_2_t_list = []\n",
    "adjacency_0_list = []\n",
    "for simplex in simplexes:\n",
    "    cell_complex = simplex.to_cell_complex()\n",
    "    cc_list.append(cell_complex)\n",
    "\n",
    "    incidence_2_t = cell_complex.incidence_matrix(rank=2).T\n",
    "    adjacency_0 = cell_complex.adjacency_matrix(rank=0)\n",
    "    incidence_2_t = torch.from_numpy(incidence_2_t.todense()).to_sparse()\n",
    "    adjacency_0 = torch.from_numpy(adjacency_0.todense()).to_sparse()\n",
    "    incidence_2_t_list.append(incidence_2_t)\n",
    "    adjacency_0_list.append(adjacency_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:55.832585216Z",
     "start_time": "2023-05-31T09:13:55.815448708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th cell complex has an incidence_2_t matrix of shape torch.Size([500, 750]).\n",
      "The 6th cell complex has an adjacency_0 matrix of shape torch.Size([252, 252]).\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th cell complex has an incidence_2_t matrix of shape {incidence_2_t_list[i_complex].shape}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th cell complex has an adjacency_0 matrix of shape {adjacency_0_list[i_complex].shape}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:13:56.672913561Z",
     "start_time": "2023-05-31T09:13:56.667986426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 5.\n"
     ]
    }
   ],
   "source": [
    "in_channels_0 = x_0s[0].shape[-1]\n",
    "in_channels_1 = x_1s[0].shape[-1]\n",
    "in_channels_2 = 5\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {in_channels_0}, {in_channels_1} and {in_channels_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:39.455212236Z",
     "start_time": "2023-05-31T09:19:39.452286461Z"
    }
   },
   "outputs": [],
   "source": [
    "class CCXN(torch.nn.Module):\n",
    "    \"\"\"CCXN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_channels_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_channels_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_0,\n",
    "        in_channels_1,\n",
    "        in_channels_2,\n",
    "        num_classes,\n",
    "        n_layers=2,\n",
    "        att=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                CCXNLayer(\n",
    "                    in_channels_0=in_channels_0,\n",
    "                    in_channels_1=in_channels_1,\n",
    "                    in_channels_2=in_channels_2,\n",
    "                    att=att,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.lin_0 = torch.nn.Linear(in_channels_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_channels_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_channels_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_0 : torch.Tensor, shape = [n_nodes, in_channels_0]\n",
    "            Input features on the nodes (0-cells).\n",
    "        x_1 : torch.Tensor, shape = [n_edges, in_channels_1]\n",
    "            Input features on the edges (1-cells).\n",
    "        neighborhood_0_to_0 : tensor, shape = [n_nodes, n_nodes]\n",
    "            Adjacency matrix of rank 0 (up).\n",
    "        neighborhood_1_to_2 : tensor, shape = [n_faces, n_edges]\n",
    "            Transpose of boundary matrix of rank 2.\n",
    "        x_2 : torch.Tensor, shape = [n_faces, in_channels_2]\n",
    "            Input features on the faces (2-cells).\n",
    "            Optional. Use for attention mechanism between edges and faces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _ : tensor, shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:40.411845803Z",
     "start_time": "2023-05-31T09:19:40.408861921Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CCXN(in_channels_0, in_channels_1, in_channels_2, num_classes=1, n_layers=2)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:41.150933630Z",
     "start_time": "2023-05-31T09:19:41.146986990Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "incidence_2_t_train, incidence_2_t_test = train_test_split(\n",
    "    incidence_2_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "adjacency_0_train, adjacency_0_test = train_test_split(\n",
    "    adjacency_0_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the CCXN using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:42.918836083Z",
     "start_time": "2023-05-31T09:19:42.114801039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 86.0653\n",
      "Epoch: 2 loss: 82.6711\n",
      "Test_loss: 40.6926\n",
      "Epoch: 3 loss: 82.3881\n",
      "Epoch: 4 loss: 81.1253\n",
      "Test_loss: 36.0267\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "        x_0, x_1, y = (\n",
    "            torch.tensor(x_0).float().to(device),\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        incidence_2_t, adjacency_0 = incidence_2_t.float().to(\n",
    "            device\n",
    "        ), adjacency_0.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                x_0, x_1, y = (\n",
    "                    torch.tensor(x_0).float().to(device),\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                incidence_2_t, adjacency_0 = incidence_2_t.float().to(\n",
    "                    device\n",
    "                ), adjacency_0.float().to(device)\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {test_loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network with Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new neural network, that uses the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:20:01.334080388Z",
     "start_time": "2023-05-31T09:20:01.303035409Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CCXN(\n",
    "    in_channels_0, in_channels_1, in_channels_2, num_classes=2, n_layers=2, att=True\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the training for this neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:21:57.205551344Z",
     "start_time": "2023-05-31T09:21:56.886478285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 79.2502\n",
      "Epoch: 2 loss: 79.2827\n",
      "Test_loss: 52.5080\n",
      "Epoch: 3 loss: 77.6260\n",
      "Epoch: 4 loss: 79.6825\n",
      "Test_loss: 36.5324\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "        x_0, x_1, y = (\n",
    "            torch.tensor(x_0).float().to(device),\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        incidence_2_t, adjacency_0 = incidence_2_t.float().to(\n",
    "            device\n",
    "        ), adjacency_0.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                x_0, x_1, y = (\n",
    "                    torch.tensor(x_0).float().to(device),\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                incidence_2_t, adjacency_0 = incidence_2_t.float().to(\n",
    "                    device\n",
    "                ), adjacency_0.float().to(device)\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "            print(f\"Test_loss: {test_loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
