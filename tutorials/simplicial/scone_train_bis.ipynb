{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial Complex Network (SCoNe)\n",
    "\n",
    "In this notebook, we will create and train a High Skip Network in the simplicial complex domain, as proposed in the paper by [Hajij et. al : High Skip Networks: A Higher Order Generalization of Skip Connections (2022)](https://openreview.net/pdf?id=Sc8glB-k6e9). \n",
    "\n",
    "We train the model to perform binary node classification using the KarateClub benchmark dataset. \n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "游린 $\\quad m_{{y \\rightarrow z \\rightarrow x}}^{(1 \\rightarrow 2 \\rightarrow 1)} = \\sigma ((L_{\\uparrow,1})_{xy} \\cdot h^{t,(1)}_y \\cdot \\Theta^{t,(1)1})$\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow z \\rightarrow x}^{(1 \\rightarrow 0 \\rightarrow 1)}  = (L_{\\downarrow,1})_{xy} \\cdot h^{t, (1)}_y \\cdot \\Theta^{t,(1)2}$    \n",
    "\n",
    "游린 $\\quad m_{{x \\rightarrow x}}^{(1 \\rightarrow 1)}  = h_x^{t,(1)} \\cdot \\Theta^{t,(1)3}$    \n",
    "\n",
    "\n",
    "游릲 $\\quad m^{(1 \\rightarrow 2 \\rightarrow 1)} = \\sum_{y \\in \\mathcal{L}_\\uparrow(x)} m_{{y \\rightarrow x}}^{(1 \\rightarrow 2 \\rightarrow 1)}$\n",
    "\n",
    "游릲 $\\quad m^{(1 \\rightarrow 0 \\rightarrow 1)}  = \\sum_{y \\in \\mathcal{L}_\\downarrow(x)} m_{y \\rightarrow z \\rightarrow x}^{(1 \\rightarrow 0 \\rightarrow 1)}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}  = m_x^{(1 \\rightarrow 2 \\rightarrow 1)} + m_x^{(1 \\rightarrow 0 \\rightarrow 1)} + m_{x \\rightarrow x}^{1 \\rightarrow 1}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(1)}  = \\sigma(m_x^{(1)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import toponetx.datasets.graph as graph\n",
    "\n",
    "from topomodelx.nn.simplicial.scone_layer_bis import SCoNeLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset\n",
    "The first step is to import the shrec16 (https://github.com/pyt-team/TopoNetX/blob/0090625d547af9536d9c30001ecfa1f19517921a/toponetx/datasets/mesh.py#L64) dataset. This dataset is a graph with 6 node features, 10 edge features, and the face normals, angles, and areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 78, 45, 11, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "dataset.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neighborhood Structures\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the lower Laplacian matrix $L_{\\downarrow, 1}$ and the upper Laplacian matrix $L_{\\uparrow,1}$ on the edges. For a santiy check, we show that the shape of the $L_{\\downarrow, 1} = n_\\text{edges} \\times n_\\text{edges}$ and $L_{\\uparrow,1} = n_\\text{edges} \\times n_\\text{edges}$. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper laplacian matrix has shape: torch.Size([78, 78]).\n",
      "The lower laplacian matrix has shape: torch.Size([78, 78]).\n"
     ]
    }
   ],
   "source": [
    "up_lap1 = dataset.up_laplacian_matrix(rank=1)\n",
    "down_lap1 = dataset.down_laplacian_matrix(rank=1)\n",
    "\n",
    "up_lap1 = torch.from_numpy(up_lap1.todense()).to_sparse()\n",
    "down_lap1 = torch.from_numpy(down_lap1.todense()).to_sparse()\n",
    "\n",
    "print(f\"The upper laplacian matrix has shape: {up_lap1.shape}.\")\n",
    "print(f\"The lower laplacian matrix has shape: {down_lap1.shape}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Labels and Preparing Input\n",
    "Gathering the edge features and using the second of the two features as a label based on its sign. The first feature will act as the input for the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = []\n",
    "edges = []\n",
    "for k, v in dataset.get_simplex_attributes(\"edge_feat\").items():\n",
    "    xy.append(v)\n",
    "xy = np.stack(xy)\n",
    "x_1 = []\n",
    "y = []\n",
    "\n",
    "for pair in xy:\n",
    "    x_1.append([pair[0]])\n",
    "    if pair[1] > 0:\n",
    "        y.append([1, 0])\n",
    "    else:\n",
    "        y.append([0, 1])\n",
    "x_1 = np.stack(x_1)\n",
    "x_1 = torch.tensor(x_1).to(device)\n",
    "y = torch.tensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([78, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split\n",
    "We split the labels into test and train sets keeping the indices to be able to calculate loss later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "indices = np.arange(78)\n",
    "y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    y, indices, test_size=test_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network\n",
    "Creating a stacked neural network that uses the SCoNeLayer class. The linear layer at the end produces an output of shape n_{nodes} x 2 so we can compare to our binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCoNeNN(torch.nn.Module):\n",
    "    \"\"\"Neural network implementation of classification using SCoNe.\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    channels : int\n",
    "        Dimension of features.\n",
    "    n_layers : int\n",
    "        Amount of message passing layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, n_layers=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                SCoNeLayer(\n",
    "                    channels=channels,\n",
    "                )\n",
    "            )\n",
    "        self.linear = torch.nn.Linear(channels, 2)\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x_1, up_lap1, down_lap1, iden):\n",
    "        \"\"\"Forward computation.\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        x_0 : tensor\n",
    "            shape = [n_nodes, channels]\n",
    "            Node features.\n",
    "\n",
    "        up_lap1 : tensor\n",
    "            shape = [n_edges, n_edges]\n",
    "            Upper Laplacian matrix of rank 1.\n",
    "\n",
    "        down_lap1 : tensor\n",
    "            shape = [n_edges, n_edges]\n",
    "            Laplacian matrix (down) of rank 1.\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        _ : tensor\n",
    "            shape = [n_nodes, 2]\n",
    "            One-hot labels assigned to nodes.\n",
    "        \"\"\"\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_1 = layer(x_1, up_lap1, down_lap1, iden)\n",
    "        x_1 = self.linear(x_1)\n",
    "        return torch.softmax(x_1, dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_channels = 1\n",
    "model = SCoNeNN(\n",
    "    channels=edge_channels,\n",
    "    n_layers=10,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping and training over data for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7211 Train_acc: 0.5323\n",
      "Epoch: 2 loss: 0.7185 Train_acc: 0.5484\n",
      "Test_acc: 0.4375\n",
      "Epoch: 3 loss: 0.7205 Train_acc: 0.5484\n",
      "Epoch: 4 loss: 0.7210 Train_acc: 0.5484\n",
      "Test_acc: 0.4375\n",
      "Epoch: 5 loss: 0.7205 Train_acc: 0.5484\n",
      "Epoch: 6 loss: 0.7194 Train_acc: 0.5484\n",
      "Test_acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajbre\\AppData\\Local\\Temp\\ipykernel_492\\1152818844.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat_test = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 6\n",
    "# WHAT ARE YOU INPUTTING/ MAKE SURE OF PROPER SIZES\n",
    "# edge classification\n",
    "dim = 78\n",
    "iden = torch.eye(dim).to_sparse()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x_1, up_lap1, down_lap1, iden)\n",
    "\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_hat[train_indices].float(), y_train.float()\n",
    "    )\n",
    "\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[train_indices] == y_train).all(dim=1).float().mean().item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    if epoch % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = torch.tensor(\n",
    "                model(x_1, up_lap1, down_lap1, iden), dtype=torch.float\n",
    "            ).to(device)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[test_indices], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
