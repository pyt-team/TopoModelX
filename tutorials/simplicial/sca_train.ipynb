{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)\n",
    "\n",
    "\n",
    "ðŸŸ¥ $\\quad m_{y \\rightarrow x}^{(r \\rightarrow r'' \\rightarrow r)} = M(h_{x}^{t, (r)}, h_{y}^{t, (r)},att(h_{x}^{t, (r)}, h_{y}^{t, (r)}),x,y,{\\Theta^t}) \\qquad \\text{where } r'' < r < r'$\n",
    "\n",
    "ðŸŸ¥ $\\quad m_{y \\rightarrow x}^{(r'' \\rightarrow r)} = M(h_{x}^{t, (r)}, h_{y}^{t, (r'')},att(h_{x}^{t, (r)}, h_{y}^{t, (r'')}),x,y,{\\Theta^t})$\n",
    "\n",
    "ðŸŸ§ $\\quad m_x^{(r \\rightarrow r)}  = AGG_{y \\in \\mathcal{L}\\_\\downarrow(x)} m_{y \\rightarrow x}^{(r \\rightarrow r)}$\n",
    "\n",
    "ðŸŸ§ $\\quad m_x^{(r'' \\rightarrow r)} = AGG_{y \\in \\mathcal{B}(x)} m_{y \\rightarrow x}^{(r'' \\rightarrow r)}$\n",
    "\n",
    "ðŸŸ© $\\quad m_x^{(r)}  = \\text{AGG}\\_{\\mathcal{N}\\_k \\in \\mathcal{N}}(m_x^{(k)})$\n",
    "\n",
    "ðŸŸ¦ $\\quad h_{x}^{t+1, (r)} = U(h_x^{t, (r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from toponetx import SimplicialComplex\n",
    "import toponetx.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from topomodelx.nn.simplicial.sca_cmps_layer import SCACMPSLayer\n",
    "from topomodelx.base.aggregation import Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available we will make use of them. Otherwise, we will use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "The first step is to import the dataset, shrec16, a benchmark dataset for 3D mesh classification. We then lift each graph into our domain of choice, a simplicial complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0`, `x_1`, and `x_2` on the nodes (0-cells), edges (1-cells), and faces (2-cells) for each complex: these will be the model's inputs,\n",
    "- a scalar classification label `y` associated to the simplicial complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 small dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec, _ = datasets.mesh.shrec_16(size=\"small\")\n",
    "\n",
    "shrec = {key: np.array(value) for key, value in shrec.items()}\n",
    "x_0s = shrec[\"node_feat\"]\n",
    "x_1s = shrec[\"edge_feat\"]\n",
    "x_2s = shrec[\"face_feat\"]\n",
    "\n",
    "ys = shrec[\"label\"]\n",
    "scs = shrec[\"complexes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th simplicial complex has 252 nodes with features of dimension 6.\n",
      "The 6th simplicial complex has 750 edges with features of dimension 10.\n",
      "The 6th simplicial complex has 500 faces with features of dimension 7.\n"
     ]
    }
   ],
   "source": [
    "i_complex = 6\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_0s[i_complex].shape[0]} nodes with features of dimension {x_0s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_1s[i_complex].shape[0]} edges with features of dimension {x_1s[i_complex].shape[1]}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The {i_complex}th simplicial complex has {x_2s[i_complex].shape[0]} faces with features of dimension {x_2s[i_complex].shape[1]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the inputs to test each message passing scheme:\n",
    "\n",
    "#### Coadjacency Message Passing Scheme (CMPS):\n",
    "This will require features from faces, and edges again, but outputs features on the edges. The first neighborhood matrix will be the level 2 lower Laplacian, $L_{\\downarrow, 2}$, and the second neighborhood matrix will be the transpose of the incidence matrix of the faces, $B_{2}^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_lap1_list = []\n",
    "down_lap2_list = []\n",
    "incidence1_t_list = []\n",
    "incidence2_t_list = []\n",
    "\n",
    "for sc in scs:\n",
    "    down_lap1 = sc.down_laplacian_matrix(rank=1)\n",
    "    down_lap2 = sc.down_laplacian_matrix(rank=2)\n",
    "    incidence_1t = sc.incidence_matrix(rank=1).T\n",
    "    incidence_2t = sc.incidence_matrix(rank=2).T\n",
    "\n",
    "    down_lap1 = torch.from_numpy(down_lap1.todense()).to_sparse()\n",
    "    down_lap2 = torch.from_numpy(down_lap2.todense()).to_sparse()\n",
    "    incidence_1t = torch.from_numpy(incidence_1t.todense()).to_sparse()\n",
    "    incidence_2t = torch.from_numpy(incidence_2t.todense()).to_sparse()\n",
    "\n",
    "    down_lap1_list.append(down_lap1)\n",
    "    down_lap2_list.append(down_lap2)\n",
    "    incidence1_t_list.append(incidence_1t)\n",
    "    incidence2_t_list.append(incidence_2t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Networks\n",
    "\n",
    "Using the SCACMPSLayer class, we create a neural network with a modifiable number of layers each following the CMPS at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_list = [x_0s[0].shape[-1], x_1s[0].shape[-1], x_2s[0].shape[-1]]\n",
    "\n",
    "complex_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMPSSCA(torch.nn.Module):\n",
    "    \"\"\"SCA with AMPS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels_list: list[int]\n",
    "        Dimension of features on each node, edge, simplex, tetahedron,... respectively\n",
    "    complex_dimension: int\n",
    "        Highest dimension of simplicial complex feature being trained on.\n",
    "    num_classes : int\n",
    "        Dimension to which the complex embeddings will be projected.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels_list,\n",
    "        complex_dim,\n",
    "        num_classes,\n",
    "        n_layers=2,\n",
    "        att=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.channels_list = channels_list\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(SCACMPSLayer(channels_list, complex_dim, att))\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.lin0 = torch.nn.Linear(channels_list[0], num_classes)\n",
    "        self.lin1 = torch.nn.Linear(channels_list[1], num_classes)\n",
    "        self.lin2 = torch.nn.Linear(channels_list[2], num_classes)\n",
    "        self.aggr = Aggregation(\n",
    "            aggr_func=\"mean\",\n",
    "            update_func=\"sigmoid\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x_list, down_lap_list, incidencet_list):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_list: list[torch.Tensor]\n",
    "            List of tensor inputs for each dimension of the complex (nodes, edges, etc.).\n",
    "        down_lap_list: list[torch.Tensor]\n",
    "            List of the down laplacian matrix for each dimension in the complex starting at edges.\n",
    "        incidencet_list: list[torch.Tensor]\n",
    "            List of the transpose incidence matrices for the edges and faces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _ : tensor, shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for i in range(self.n_layers):\n",
    "            x_list = self.layers[i](x_list, down_lap_list, incidencet_list)\n",
    "\n",
    "        x_0 = self.lin0(x_list[0])\n",
    "        x_1 = self.lin1(x_list[1])\n",
    "        x_2 = self.lin2(x_list[2])\n",
    "\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "\n",
    "        x_2f = torch.flatten(two_dimensional_cells_mean)\n",
    "        x_1f = torch.flatten(one_dimensional_cells_mean)\n",
    "        x_0f = torch.flatten(zero_dimensional_cells_mean)\n",
    "\n",
    "        return x_0f + x_1f + x_2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0s, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1s, test_size=test_size, shuffle=False)\n",
    "x_2_train, x_2_test = train_test_split(x_2s, test_size=test_size, shuffle=False)\n",
    "\n",
    "down_lap1_train, down_lap1_test = train_test_split(\n",
    "    down_lap1_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "down_lap2_train, down_lap2_test = train_test_split(\n",
    "    down_lap2_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence1_t_train, incidence1_t_test = train_test_split(\n",
    "    incidence1_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "incidence2_t_train, incidence2_t_test = train_test_split(\n",
    "    incidence2_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "\n",
    "y_train, y_test = train_test_split(ys, test_size=test_size, shuffle=False)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Model\n",
    "Because the SCA implementation in [HZPMC22]_ was used for clustering, we did the same in one dimension to train on the int classification labels provided my the shrec16 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AMPSSCA(\n",
    "    channels_list=channels_list,\n",
    "    complex_dim=complex_dim,\n",
    "    num_classes=1,\n",
    "    n_layers=3,\n",
    "    att=False,\n",
    ")\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 210.15074526998214\n",
      "Test_loss: 310.42108154296875\n",
      "Accuracy: 0.0\n",
      "Epoch: 2 loss: 117.16418675570749\n",
      "Test_loss: 182.73768615722656\n",
      "Accuracy: 0.0\n",
      "Epoch: 3 loss: 86.16661446671351\n",
      "Test_loss: 124.76749420166016\n",
      "Accuracy: 0.15\n",
      "Epoch: 4 loss: 77.8968961050734\n",
      "Test_loss: 98.735595703125\n",
      "Accuracy: 0.0\n",
      "Epoch: 5 loss: 75.84987897076644\n",
      "Test_loss: 86.7345199584961\n",
      "Accuracy: 0.0\n",
      "Epoch: 6 loss: 75.18321903655306\n",
      "Test_loss: 80.809326171875\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_interval = 1\n",
    "num_epochs = 6\n",
    "\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for x_0, x_1, x_2, down_lap1, down_lap2, incidence_1t, incidence_2t, y in zip(\n",
    "        x_0_train,\n",
    "        x_1_train,\n",
    "        x_2_train,\n",
    "        down_lap1_train,\n",
    "        down_lap2_train,\n",
    "        incidence1_t_train,\n",
    "        incidence2_t_train,\n",
    "        y_train,\n",
    "    ):\n",
    "        x_0, x_1, x_2, y = (\n",
    "            torch.tensor(x_0).float().to(device),\n",
    "            torch.tensor(x_1).float().to(device),\n",
    "            torch.tensor(x_2).float().to(device),\n",
    "            torch.tensor(y).float().to(device),\n",
    "        )\n",
    "        x_list = [x_0, x_1, x_2]\n",
    "\n",
    "        down_lap1 = down_lap1.float().to(device)\n",
    "        down_lap2 = down_lap2.float().to(device)\n",
    "        down_lap_list = [down_lap1, down_lap2]\n",
    "\n",
    "        incidence_1t = incidence_1t.float().to(device)\n",
    "        incidence_2t = incidence_2t.float().to(device)\n",
    "        incidence_t_list = [incidence_1t, incidence_2t]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_list, down_lap_list, incidence_t_list)\n",
    "        loss = loss_fn(y_hat.flatten(), y)\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss)}\",\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    if epoch_i % test_interval == 0:\n",
    "        correct_count = 0\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                down_lap1,\n",
    "                down_lap2,\n",
    "                incidence_1t,\n",
    "                incidence_2t,\n",
    "                y,\n",
    "            ) in zip(\n",
    "                x_0_test,\n",
    "                x_1_test,\n",
    "                x_2_test,\n",
    "                down_lap1_test,\n",
    "                down_lap2_test,\n",
    "                incidence1_t_test,\n",
    "                incidence2_t_test,\n",
    "                y_test,\n",
    "            ):\n",
    "                x_0, x_1, x_2, y = (\n",
    "                    torch.tensor(x_0).float().to(device),\n",
    "                    torch.tensor(x_1).float().to(device),\n",
    "                    torch.tensor(x_2).float().to(device),\n",
    "                    torch.tensor(y).float().to(device),\n",
    "                )\n",
    "                x_list = [x_0, x_1, x_2]\n",
    "\n",
    "                down_lap1 = down_lap1.float().to(device)\n",
    "                down_lap2 = down_lap2.float().to(device)\n",
    "                down_lap_list = [down_lap1, down_lap2]\n",
    "\n",
    "                incidence_1t = incidence_1t.float().to(device)\n",
    "                incidence_2t = incidence_2t.float().to(device)\n",
    "                incidence_t_list = [incidence_1t, incidence_2t]\n",
    "\n",
    "                y_hat = model(x_list, down_lap_list, incidence_t_list)\n",
    "                test_loss = loss_fn(y_hat, y)\n",
    "\n",
    "                if round(y_hat.item()) == round(y.item()):\n",
    "                    correct_count += 1\n",
    "\n",
    "            print(f\"Test_loss: {test_loss}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
