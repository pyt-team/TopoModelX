{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Simplicial High-Skip Network (HSN)\n",
    "\n",
    "In this notebook, we will create and train a High Skip Network in the simplicial complex domain, as proposed in the paper by [Hajij et. al : High Skip Networks: A Higher Order Generalization of Skip Connections (2022)](https://openreview.net/pdf?id=Sc8glB-k6e9). \n",
    "\n",
    "We train the model to perform binary node classification using the KarateClub benchmark dataset. \n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "游린 $\\quad m_{{y \\rightarrow z}}^{(0 \\rightarrow 0)} = \\sigma ((A_{\\uparrow,0})_{xy} \\cdot h^{t,(0)}_y \\cdot \\Theta^{t,(0)1})$    (level 1)\n",
    "\n",
    "游린 $\\quad m_{z \\rightarrow x}^{(0 \\rightarrow 0)}  = (A_{\\uparrow,0})_{xy} \\cdot m_{y \\rightarrow z}^{(0 \\rightarrow 0)} \\cdot \\Theta^{t,(0)2}$    (level 2)\n",
    "\n",
    "游린 $\\quad m_{{y \\rightarrow z}}^{(0 \\rightarrow 1)}  = \\sigma((B_1^T)_{zy} \\cdot h_y^{t,(0)} \\cdot \\Theta^{t,(0 \\rightarrow 1)})$    (level 1)\n",
    "\n",
    "游린 $\\quad m_{z \\rightarrow x)}^{(1 \\rightarrow 0)}  = (B_1)_{xz} \\cdot m_{z \\rightarrow x}^{(0 \\rightarrow 1)} \\cdot \\Theta^{t, (1 \\rightarrow 0)}$    (level 2)\n",
    "\n",
    "游릲 $\\quad m_{x}^{(0 \\rightarrow 0)}  = \\sum_{z \\in \\mathcal{L}_\\uparrow(x)} m_{z \\rightarrow x}^{(0 \\rightarrow 0)}$\n",
    "\n",
    "游릲 $\\quad m_{x}^{(1 \\rightarrow 0)}  = \\sum_{z \\in \\mathcal{C}(x)} m_{z \\rightarrow x}^{(1 \\rightarrow 0)}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}  = m_x^{(0 \\rightarrow 0)} + m_x^{(1 \\rightarrow 0)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)}  = I(m_x^{(0)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import toponetx.datasets.graph as graph\n",
    "import torch\n",
    "\n",
    "from topomodelx.nn.simplicial.hsn import HSN\n",
    "from topomodelx.utils.sparse import from_sparse\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import dataset ##\n",
    "\n",
    "The first step is to import the Karate Club (https://www.jstor.org/stable/3629752) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.\n",
    "\n",
    "We must first lift our graph dataset into the simplicial complex domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4\n"
     ]
    }
   ],
   "source": [
    "dataset = graph.karate_club(complex_type=\"simplicial\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the boundary matrix (or incidence matrix) $B_1$ and the adjacency matrix $A_{\\uparrow,0}$ on the nodes. For a santiy check, we show that the shape of the $B_1 = n_\\text{nodes} \\times n_\\text{edges}$ and $A_{\\uparrow,0} = n_\\text{nodes} \\times n_\\text{nodes}$. We also convert the neighborhood structures to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The incidence matrix B1 has shape: torch.Size([34, 78]).\n",
      "The adjacency matrix A0 has shape: torch.Size([34, 34]).\n"
     ]
    }
   ],
   "source": [
    "incidence_1 = dataset.incidence_matrix(rank=1)\n",
    "adjacency_0 = dataset.adjacency_matrix(rank=0)\n",
    "\n",
    "incidence_1 = from_sparse(incidence_1)\n",
    "adjacency_0 = from_sparse(adjacency_0)\n",
    "\n",
    "print(f\"The incidence matrix B1 has shape: {incidence_1.shape}.\")\n",
    "print(f\"The adjacency matrix A0 has shape: {adjacency_0.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import signal ##\n",
    "\n",
    "Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape $n_\\text{nodes} \\times$ in_channels, where in_channels is the dimension of each cell's feature. Here, we have in_channels = channels_nodes $ = 34$. This is because the Karate dataset encodes the identity of each of the 34 nodes as a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = list(dataset.get_simplex_attributes(\"node_feat\").values())\n",
    "x_0 = torch.tensor(np.stack(x_0))\n",
    "channels_nodes = x_0.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34 nodes with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_0.shape[0]} nodes with features of dimension {x_0.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load edge features, this is how we would do it (note that we will not use these features for this model, and this serves simply as a demonstration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = list(dataset.get_simplex_attributes(\"edge_feat\").values())\n",
    "x_1 = np.stack(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 78 edges with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_1.shape[0]} edges with features of dimension {x_1.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for face features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = list(dataset.get_simplex_attributes(\"face_feat\").values())\n",
    "x_2 = np.stack(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45 faces with features of dimension 2.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {x_2.shape[0]} faces with features of dimension {x_2.shape[1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define binary labels\n",
    "We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.\n",
    "\n",
    "We convert the binary labels into one-hot encoder form, and keep the first four nodes' true labels for the purpose of testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        1,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        1,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "        0,\n",
    "    ]\n",
    ")\n",
    "y_true = np.zeros((34, 2))\n",
    "y_true[:, 0] = y\n",
    "y_true[:, 1] = 1 - y\n",
    "y_train = y_true[:30]\n",
    "y_test = y_true[-4:]\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the HSN class, we create our neural network with stacked layers. Given the considered dataset and task (Karate Club, node classification), a linear layer at the end produces an output with shape $n_\\text{nodes} \\times 2$, so we can compare with our binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, channels, out_channels, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.base_model = HSN(\n",
    "            channels=channels,\n",
    "            n_layers=n_layers,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(channels, out_channels)\n",
    "\n",
    "    def forward(self, x, incidence_1, adjacency_0):\n",
    "        x = self.base_model(x, incidence_1, adjacency_0)\n",
    "        x = self.linear(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 2\n",
    "n_layers = 2\n",
    "\n",
    "model = Network(\n",
    "    channels=channels_nodes,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=2,\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "The following cell performs the training, looping over the network for a low number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 0.7200 Train_acc: 0.5667\n",
      "Epoch: 2 loss: 0.7183 Train_acc: 0.5667\n",
      "Epoch: 3 loss: 0.7167 Train_acc: 0.5667\n",
      "Epoch: 4 loss: 0.7153 Train_acc: 0.5667\n",
      "Epoch: 5 loss: 0.7142 Train_acc: 0.5667\n",
      "Epoch: 6 loss: 0.7133 Train_acc: 0.5667\n",
      "Epoch: 7 loss: 0.7125 Train_acc: 0.5667\n",
      "Epoch: 8 loss: 0.7118 Train_acc: 0.5667\n",
      "Epoch: 9 loss: 0.7111 Train_acc: 0.5667\n",
      "Epoch: 10 loss: 0.7105 Train_acc: 0.5667\n",
      "Test_acc: 0.0000\n",
      "Epoch: 11 loss: 0.7099 Train_acc: 0.5667\n",
      "Epoch: 12 loss: 0.7093 Train_acc: 0.5667\n",
      "Epoch: 13 loss: 0.7087 Train_acc: 0.5667\n",
      "Epoch: 14 loss: 0.7081 Train_acc: 0.5667\n",
      "Epoch: 15 loss: 0.7076 Train_acc: 0.5667\n",
      "Epoch: 16 loss: 0.7070 Train_acc: 0.5667\n",
      "Epoch: 17 loss: 0.7066 Train_acc: 0.5667\n",
      "Epoch: 18 loss: 0.7061 Train_acc: 0.6000\n",
      "Epoch: 19 loss: 0.7058 Train_acc: 0.5667\n",
      "Epoch: 20 loss: 0.7054 Train_acc: 0.5667\n",
      "Test_acc: 0.2500\n",
      "Epoch: 21 loss: 0.7050 Train_acc: 0.5667\n",
      "Epoch: 22 loss: 0.7046 Train_acc: 0.5667\n",
      "Epoch: 23 loss: 0.7042 Train_acc: 0.5667\n",
      "Epoch: 24 loss: 0.7037 Train_acc: 0.5667\n",
      "Epoch: 25 loss: 0.7033 Train_acc: 0.5667\n",
      "Epoch: 26 loss: 0.7029 Train_acc: 0.5667\n",
      "Epoch: 27 loss: 0.7025 Train_acc: 0.5667\n",
      "Epoch: 28 loss: 0.7021 Train_acc: 0.5667\n",
      "Epoch: 29 loss: 0.7017 Train_acc: 0.5333\n",
      "Epoch: 30 loss: 0.7013 Train_acc: 0.5333\n",
      "Test_acc: 0.5000\n",
      "Epoch: 31 loss: 0.7009 Train_acc: 0.5667\n",
      "Epoch: 32 loss: 0.7005 Train_acc: 0.5667\n",
      "Epoch: 33 loss: 0.7001 Train_acc: 0.5667\n",
      "Epoch: 34 loss: 0.6997 Train_acc: 0.5333\n",
      "Epoch: 35 loss: 0.6993 Train_acc: 0.5333\n",
      "Epoch: 36 loss: 0.6989 Train_acc: 0.5667\n",
      "Epoch: 37 loss: 0.6985 Train_acc: 0.5667\n",
      "Epoch: 38 loss: 0.6981 Train_acc: 0.5333\n",
      "Epoch: 39 loss: 0.6977 Train_acc: 0.5333\n",
      "Epoch: 40 loss: 0.6973 Train_acc: 0.5667\n",
      "Test_acc: 0.5000\n",
      "Epoch: 41 loss: 0.6969 Train_acc: 0.5667\n",
      "Epoch: 42 loss: 0.6966 Train_acc: 0.5667\n",
      "Epoch: 43 loss: 0.6962 Train_acc: 0.5667\n",
      "Epoch: 44 loss: 0.6958 Train_acc: 0.5667\n",
      "Epoch: 45 loss: 0.6955 Train_acc: 0.5667\n",
      "Epoch: 46 loss: 0.6951 Train_acc: 0.5667\n",
      "Epoch: 47 loss: 0.6948 Train_acc: 0.5667\n",
      "Epoch: 48 loss: 0.6945 Train_acc: 0.5667\n",
      "Epoch: 49 loss: 0.6942 Train_acc: 0.5667\n",
      "Epoch: 50 loss: 0.6938 Train_acc: 0.5667\n",
      "Test_acc: 0.5000\n",
      "Epoch: 51 loss: 0.6935 Train_acc: 0.5667\n",
      "Epoch: 52 loss: 0.6932 Train_acc: 0.5667\n",
      "Epoch: 53 loss: 0.6929 Train_acc: 0.5667\n",
      "Epoch: 54 loss: 0.6927 Train_acc: 0.5667\n",
      "Epoch: 55 loss: 0.6924 Train_acc: 0.5667\n",
      "Epoch: 56 loss: 0.6921 Train_acc: 0.5667\n",
      "Epoch: 57 loss: 0.6919 Train_acc: 0.5667\n",
      "Epoch: 58 loss: 0.6916 Train_acc: 0.5667\n",
      "Epoch: 59 loss: 0.6914 Train_acc: 0.5667\n",
      "Epoch: 60 loss: 0.6911 Train_acc: 0.5667\n",
      "Test_acc: 0.5000\n",
      "Epoch: 61 loss: 0.6909 Train_acc: 0.5667\n",
      "Epoch: 62 loss: 0.6907 Train_acc: 0.5667\n",
      "Epoch: 63 loss: 0.6905 Train_acc: 0.5667\n",
      "Epoch: 64 loss: 0.6903 Train_acc: 0.6000\n",
      "Epoch: 65 loss: 0.6901 Train_acc: 0.6000\n",
      "Epoch: 66 loss: 0.6899 Train_acc: 0.6000\n",
      "Epoch: 67 loss: 0.6897 Train_acc: 0.6000\n",
      "Epoch: 68 loss: 0.6895 Train_acc: 0.6000\n",
      "Epoch: 69 loss: 0.6893 Train_acc: 0.6000\n",
      "Epoch: 70 loss: 0.6892 Train_acc: 0.6000\n",
      "Test_acc: 0.5000\n",
      "Epoch: 71 loss: 0.6890 Train_acc: 0.6000\n",
      "Epoch: 72 loss: 0.6888 Train_acc: 0.6000\n",
      "Epoch: 73 loss: 0.6887 Train_acc: 0.6000\n",
      "Epoch: 74 loss: 0.6885 Train_acc: 0.6000\n",
      "Epoch: 75 loss: 0.6884 Train_acc: 0.6000\n",
      "Epoch: 76 loss: 0.6883 Train_acc: 0.6000\n",
      "Epoch: 77 loss: 0.6881 Train_acc: 0.6000\n",
      "Epoch: 78 loss: 0.6880 Train_acc: 0.6000\n",
      "Epoch: 79 loss: 0.6879 Train_acc: 0.6000\n",
      "Epoch: 80 loss: 0.6878 Train_acc: 0.6000\n",
      "Test_acc: 0.5000\n",
      "Epoch: 81 loss: 0.6876 Train_acc: 0.6000\n",
      "Epoch: 82 loss: 0.6875 Train_acc: 0.6000\n",
      "Epoch: 83 loss: 0.6874 Train_acc: 0.6000\n",
      "Epoch: 84 loss: 0.6873 Train_acc: 0.6000\n",
      "Epoch: 85 loss: 0.6872 Train_acc: 0.6000\n",
      "Epoch: 86 loss: 0.6871 Train_acc: 0.6000\n",
      "Epoch: 87 loss: 0.6870 Train_acc: 0.6000\n",
      "Epoch: 88 loss: 0.6869 Train_acc: 0.6000\n",
      "Epoch: 89 loss: 0.6868 Train_acc: 0.6000\n",
      "Epoch: 90 loss: 0.6868 Train_acc: 0.6000\n",
      "Test_acc: 0.5000\n",
      "Epoch: 91 loss: 0.6867 Train_acc: 0.6000\n",
      "Epoch: 92 loss: 0.6866 Train_acc: 0.6000\n",
      "Epoch: 93 loss: 0.6865 Train_acc: 0.6000\n",
      "Epoch: 94 loss: 0.6864 Train_acc: 0.6000\n",
      "Epoch: 95 loss: 0.6864 Train_acc: 0.6000\n",
      "Epoch: 96 loss: 0.6863 Train_acc: 0.6000\n",
      "Epoch: 97 loss: 0.6862 Train_acc: 0.6000\n",
      "Epoch: 98 loss: 0.6862 Train_acc: 0.6000\n",
      "Epoch: 99 loss: 0.6861 Train_acc: 0.6000\n",
      "Epoch: 100 loss: 0.6860 Train_acc: 0.6000\n",
      "Test_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "test_interval = 10\n",
    "num_epochs = 100\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat = model(x_0, incidence_1, adjacency_0)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "        y_hat[: len(y_train)].float(), y_train.float()\n",
    "    )\n",
    "    epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    y_pred = torch.where(y_hat > 0.5, torch.tensor(1), torch.tensor(0))\n",
    "    accuracy = (y_pred[-len(y_train) :] == y_train).all(dim=1).float().mean().item()\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {accuracy:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat_test = model(x_0, incidence_1, adjacency_0)\n",
    "            y_pred_test = torch.where(\n",
    "                y_hat_test > 0.5, torch.tensor(1), torch.tensor(0)\n",
    "            )\n",
    "            test_accuracy = (\n",
    "                torch.eq(y_pred_test[-len(y_test) :], y_test)\n",
    "                .all(dim=1)\n",
    "                .float()\n",
    "                .mean()\n",
    "                .item()\n",
    "            )\n",
    "            print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
