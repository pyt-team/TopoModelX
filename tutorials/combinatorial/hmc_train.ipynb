{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Convolutional Cell Complex Network (CCXN)\n",
    "\n",
    "We create and train a simplified version of the CCXN originally proposed in [Hajij et. al : Cell Complex Neural Networks (2020)](https://arxiv.org/pdf/2010.00743.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "1. A convolution from nodes to nodes using an adjacency message passing scheme (AMPS):\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(0 \\rightarrow 1 \\rightarrow 0)} = M_{\\mathcal{L}_\\uparrow}^t(h_x^{t,(0)}, h_y^{t,(0)}, \\Theta^{t,(y \\rightarrow x)})$ \n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1 \\rightarrow 0)} = AGG_{y \\in \\mathcal{L}_\\uparrow(x)}(m_{y \\rightarrow \\{z\\} \\rightarrow x}^{0 \\rightarrow 1 \\rightarrow 0})$ \n",
    "\n",
    "游릴 $\\quad m_x^{(0)} = m_x^{(0 \\rightarrow 1 \\rightarrow 0)}$ \n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = U^{t}(h_x^{t,(0)}, m_x^{(0)})$\n",
    "\n",
    "2. A convolution from edges to faces using a cohomology message passing scheme:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = M^t_{\\mathcal{C}}(h_{x}^{t,(r)}, h_y^{t,(r')}, x, y)$ \n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)}  = AGG_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릱 $\\quad h_{x}^{t+1,(r)} = U^{t,(r)}(h_{x}^{t,(r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031).\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:25:42.527025Z",
     "start_time": "2023-06-09T15:25:40.555941Z"
=======
     "end_time": "2023-06-09T21:03:28.958807Z",
     "start_time": "2023-06-09T21:03:28.952705Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:26:15.578356Z",
     "start_time": "2023-06-09T15:26:15.572682Z"
=======
     "end_time": "2023-06-09T21:03:30.160175Z",
     "start_time": "2023-06-09T21:03:30.152360Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification.\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:26:23.504585Z",
     "start_time": "2023-06-09T15:26:17.665297Z"
    }
   },
=======
   "execution_count": 17,
>>>>>>> 6d4b371 (Def neighborhood structures)
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping the files...\n",
      "\n",
      "done!\n",
      "Loading dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "dataset = TUDataset(\n",
    "    root=\"/tmp/MUTAG\", name=\"MUTAG\", use_edge_attr=True, use_node_attr=True\n",
    ")\n",
    "dataset = dataset[:20]\n",
    "cc_list = []\n",
    "x_0_list = []\n",
    "x_1_list = []\n",
    "y_list = []\n",
    "for graph in dataset:\n",
    "    cell_complex = CombinatorialComplex(to_networkx(graph))\n",
    "    cc_list.append(cell_complex)\n",
    "    x_0_list.append(graph.x)\n",
    "    x_1_list.append(graph.edge_attr)\n",
    "    y_list.append(int(graph.y))\n",
    "\n",
    "i_cc = 0\n",
    "print(f\"Features on nodes for the {i_cc}th cell complex: {x_0_list[i_cc].shape}.\")\n",
    "print(f\"Features on edges for the {i_cc}th cell complex: {x_1_list[i_cc].shape}.\")\n",
    "print(f\"Label of {i_cc}th cell complex: {y_list[i_cc]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.567542  ,  0.570995  , -0.210023  , -0.06894332,  0.72564355,\n         0.6846081 ],\n       [ 0.603908  ,  0.557968  , -0.223298  ,  0.91155493,  0.37192256,\n         0.17533174],\n       [ 0.591494  ,  0.464737  ,  0.350567  ,  0.33390166,  0.55019138,\n         0.76537515],\n       ...,\n       [-0.331773  , -0.33001   ,  0.049767  , -0.28529544, -0.95405566,\n        -0.09156586],\n       [-0.401883  , -0.263047  ,  0.136766  , -0.66302596, -0.62547973,\n         0.41130485],\n       [ 0.261249  ,  0.128185  ,  0.304997  ,  0.7728916 , -0.44845904,\n         0.44891321]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
=======
>>>>>>> 6d4b371 (Def neighborhood structures)
    "shrec_training, shrec_testing = shrec_16()\n",
    "\n",
    "# training dataset\n",
    "training_complexes = shrec_training[\"complexes\"]\n",
    "training_labels = shrec_training[\"label\"]\n",
    "training_node_feat = shrec_training[\"node_feat\"]\n",
    "training_edge_feat = shrec_training[\"edge_feat\"]\n",
    "training_face_feat = shrec_training[\"face_feat\"]\n",
    "\n",
    "# testing dataset\n",
    "testing_complexes = shrec_testing[\"complexes\"]\n",
    "testing_labels = shrec_testing[\"label\"]\n",
    "testing_node_feat = shrec_testing[\"node_feat\"]\n",
    "testing_edge_feat = shrec_testing[\"edge_feat\"]\n",
    "testing_face_feat = shrec_testing[\"face_feat\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:26:56.919010Z",
     "start_time": "2023-06-09T15:26:56.915717Z"
=======
     "end_time": "2023-06-09T21:04:29.426688Z",
     "start_time": "2023-06-09T21:04:17.338842Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "array([[1.22957341, 0.13581241, 0.45991269, ..., 2.25198965, 2.89552337,\n        2.00058261],\n       [1.43636325, 0.14296384, 0.58913082, ..., 1.74326848, 2.89552337,\n        0.51764337],\n       [0.96944867, 0.11326229, 0.70546737, ..., 2.4000534 , 2.25383585,\n        0.468195  ],\n       ...,\n       [0.39824646, 0.12369258, 0.55931499, ..., 0.945035  , 0.59602236,\n        4.14184985],\n       [0.19510851, 0.11228415, 1.07026534, ..., 3.67055053, 2.41476323,\n        0.51704672],\n       [0.0621548 , 0.122271  , 1.95575932, ..., 2.90562928, 1.5314299 ,\n        0.66267758]])"
=======
      "text/plain": "array([[ 0.567542  ,  0.570995  , -0.210023  , -0.06894332,  0.72564355,\n         0.6846081 ],\n       [ 0.603908  ,  0.557968  , -0.223298  ,  0.91155493,  0.37192256,\n         0.17533174],\n       [ 0.591494  ,  0.464737  ,  0.350567  ,  0.33390166,  0.55019138,\n         0.76537515],\n       ...,\n       [-0.331773  , -0.33001   ,  0.049767  , -0.28529544, -0.95405566,\n        -0.09156586],\n       [-0.401883  , -0.263047  ,  0.136766  , -0.66302596, -0.62547973,\n         0.41130485],\n       [ 0.261249  ,  0.128185  ,  0.304997  ,  0.7728916 , -0.44845904,\n         0.44891321]])"
>>>>>>> 6d4b371 (Def neighborhood structures)
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\"\"\"\n",
    "\n",
    "training_node_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:26:58.068662Z",
     "start_time": "2023-06-09T15:26:58.061951Z"
=======
     "end_time": "2023-06-09T21:04:30.525533Z",
     "start_time": "2023-06-09T21:04:30.522733Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "array([[ 6.16026555e-04,  3.42332662e-01,  9.39444198e-01, ...,\n         9.55859971e-01,  4.28478956e-01,  1.75725373e+00],\n       [ 6.81088138e-04,  3.97494225e-01,  1.96188417e-01, ...,\n         4.59912686e-01,  1.33996485e+00,  1.34171512e+00],\n       [ 2.02495554e-03, -7.65949901e-01,  4.13444548e-01, ...,\n         1.32871011e+00,  1.22375172e+00,  5.89130819e-01],\n       ...,\n       [ 1.88118714e-03,  1.16577970e-01, -9.84528932e-01, ...,\n         3.64363423e-01,  1.93855641e+00,  8.38672818e-01],\n       [ 1.50431667e-03, -4.34561991e-01, -8.48251445e-01, ...,\n         1.54860901e+00,  5.77114229e-01,  1.01586942e+00],\n       [ 1.74908308e-03, -8.97968600e-01, -3.36066581e-01, ...,\n         1.04615878e+00,  1.50159627e+00,  5.93837603e-01]])"
     },
     "execution_count": 6,
=======
      "text/plain": "array([[1.22957341, 0.13581241, 0.45991269, ..., 2.25198965, 2.89552337,\n        2.00058261],\n       [1.43636325, 0.14296384, 0.58913082, ..., 1.74326848, 2.89552337,\n        0.51764337],\n       [0.96944867, 0.11326229, 0.70546737, ..., 2.4000534 , 2.25383585,\n        0.468195  ],\n       ...,\n       [0.39824646, 0.12369258, 0.55931499, ..., 0.945035  , 0.59602236,\n        4.14184985],\n       [0.19510851, 0.11228415, 1.07026534, ..., 3.67055053, 2.41476323,\n        0.51704672],\n       [0.0621548 , 0.122271  , 1.95575932, ..., 2.90562928, 1.5314299 ,\n        0.66267758]])"
     },
     "execution_count": 19,
>>>>>>> 6d4b371 (Def neighborhood structures)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
<<<<<<< HEAD
   "source": [
    "training_complexes[0].to_trimesh().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T15:27:03.186480Z",
     "start_time": "2023-06-09T15:27:03.182988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
=======
>>>>>>> 6d4b371 (Def neighborhood structures)
   "source": [
    "\"\"\"\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\"\"\"\n",
    "\n",
    "training_edge_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:27:10.006172Z",
     "start_time": "2023-06-09T15:27:10.000404Z"
=======
     "end_time": "2023-06-09T21:04:31.634859Z",
     "start_time": "2023-06-09T21:04:31.629208Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   }
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T15:28:16.622681Z",
     "start_time": "2023-06-09T15:27:59.717932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "CombinatorialComplex(name=)"
     },
     "execution_count": 9,
=======
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 6.16026555e-04,  3.42332662e-01,  9.39444198e-01, ...,\n         9.55859971e-01,  4.28478956e-01,  1.75725373e+00],\n       [ 6.81088138e-04,  3.97494225e-01,  1.96188417e-01, ...,\n         4.59912686e-01,  1.33996485e+00,  1.34171512e+00],\n       [ 2.02495554e-03, -7.65949901e-01,  4.13444548e-01, ...,\n         1.32871011e+00,  1.22375172e+00,  5.89130819e-01],\n       ...,\n       [ 1.88118714e-03,  1.16577970e-01, -9.84528932e-01, ...,\n         3.64363423e-01,  1.93855641e+00,  8.38672818e-01],\n       [ 1.50431667e-03, -4.34561991e-01, -8.48251445e-01, ...,\n         1.54860901e+00,  5.77114229e-01,  1.01586942e+00],\n       [ 1.74908308e-03, -8.97968600e-01, -3.36066581e-01, ...,\n         1.04615878e+00,  1.50159627e+00,  5.93837603e-01]])"
     },
     "execution_count": 21,
>>>>>>> 6d4b371 (Def neighborhood structures)
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n",
    "\"\"\"\n",
    "\n",
    "training_face_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
<<<<<<< HEAD
     "end_time": "2023-06-09T15:29:07.944383Z",
     "start_time": "2023-06-09T15:29:07.940283Z"
=======
     "end_time": "2023-06-09T21:04:35.626961Z",
     "start_time": "2023-06-09T21:04:35.618685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#training_complexes[0].to_trimesh().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:03:52.655644Z",
     "start_time": "2023-06-09T21:03:52.652309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "for i in range(len(training_complexes)):\n",
    "    training_complexes[i] = training_complexes[i].to_combinatorial_complex()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:05:12.218607Z",
     "start_time": "2023-06-09T21:04:53.570232Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:37:06.801153Z",
     "start_time": "2023-06-09T15:37:06.796903Z"
    }
   },
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Implementing the CCXN architecture will require to perform message passing along neighborhood structures of the cell complexes.\n",
    "\n",
    "Thus, now we retrieve these neighborhood structures (i.e. their representative matrices) that we will use to send messages. \n",
    "\n",
    "For the CCXN, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0, 1, 1, ..., 0, 0, 0],\n        [1, 0, 1, ..., 0, 0, 0],\n        [1, 1, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 1],\n        [0, 0, 0, ..., 0, 1, 0]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:42:07.974975Z",
     "start_time": "2023-06-09T15:41:47.763379Z"
=======
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T21:10:40.979713Z",
     "start_time": "2023-06-09T21:10:19.667111Z"
>>>>>>> 6d4b371 (Def neighborhood structures)
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "tensor([[0, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 0, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [0, 0, 0,  ..., 0, 1, 0]])\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_1_t transpose of the 0-th complex: torch.Size([750, 252]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n",
      "Incidence_2_t transpose of the 0-th complex: torch.Size([500, 750]).\n"
     ]
    }
   ],
   "source": [
    "adjacency_0_list = []\n",
    "coadjacency_2_list = []\n",
    "incidence_1_list = []\n",
    "incidence_1_t_list = []\n",
    "incidence_2_list = []\n",
    "incidence_2_t_list = []\n",
    "\n",
    "for cc in training_complexes:\n",
    "\n",
    "    adjacency_0 = torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse()\n",
    "    coadjacency_2 = torch.from_numpy(cc.coadjacency_matrix(2,1).todense()).to_sparse()\n",
    "\n",
    "    incidence_1 = torch.from_numpy(cc.incidence_matrix(1,0).todense()).to_sparse()\n",
    "    incidence_1_t = incidence_1.transpose(1,0)\n",
    "\n",
    "    incidence_2 = torch.from_numpy(cc.incidence_matrix(2,1).todense()).to_sparse()\n",
    "    incidence_2_t = incidence_2.transpose(1,0)\n",
    "\n",
    "    adjacency_0_list.append(adjacency_0)\n",
    "    coadjacency_2_list.append(coadjacency_2)\n",
    "    incidence_1_list.append(incidence_1)\n",
    "    incidence_1_t_list.append(incidence_1_t)\n",
    "    incidence_2_list.append(incidence_2)\n",
    "    incidence_2_t_list.append(incidence_2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_1_t transpose of the 0-th complex: torch.Size([750, 252]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n",
      "Incidence_2_t transpose of the 0-th complex: torch.Size([500, 750]).\n"
     ]
    }
   ],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_list[i_cc].shape}.\")\n",
    "print(f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_1_t transpose of the {i_cc}-th complex: {incidence_1_t_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2_t transpose of the {i_cc}-th complex: {incidence_2_t_list[i_cc].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:10:53.194836Z",
     "start_time": "2023-06-09T21:10:53.190783Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:47:58.549790Z",
     "start_time": "2023-06-09T15:47:58.546827Z"
    }
   },
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency of the 1-th complex: torch.Size([252, 252]).\n",
      "Coadjacency of the 1-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 1-th complex: torch.Size([252, 750]).\n",
      "Incidence_1_t of the 1-th complex: torch.Size([750, 252]).\n",
      "Incidence_2 of the 1-th complex: torch.Size([750, 500]).\n",
      "Incidence_2_t of the 1-th complex: torch.Size([500, 750]).\n",
      "torch.Size([750, 500]) torch.Size([500, 750])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T14:51:42.331158Z",
     "start_time": "2023-06-09T14:51:42.325815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 1, 1,  ..., 0, 0, 0],\n        [1, 0, 1,  ..., 0, 0, 0],\n        [1, 1, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 1, 1],\n        [0, 0, 0,  ..., 1, 0, 1],\n        [0, 0, 0,  ..., 1, 1, 0]])"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_0 = training_node_feat[0].shape[-1]\n",
    "d_1 = training_edge_feat[0].shape[-1]\n",
    "d_2 = training_face_feat[0].shape[-1]\n",
    "\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:39.455212236Z",
     "start_time": "2023-05-31T09:19:39.452286461Z"
    }
   },
   "outputs": [],
   "source": [
    "class CCXN(torch.nn.Module):\n",
    "    \"\"\"CCXN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels_0 : int\n",
    "        Dimension of input features on nodes.\n",
    "    in_channels_1 : int\n",
    "        Dimension of input features on edges.\n",
    "    in_channels_2 : int\n",
    "        Dimension of input features on faces.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    att : bool\n",
    "        Whether to use attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels_0,\n",
    "        in_channels_1,\n",
    "        in_channels_2,\n",
    "        num_classes,\n",
    "        n_layers=2,\n",
    "        att=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(\n",
    "                CCXNLayer(\n",
    "                    in_channels_0=in_channels_0,\n",
    "                    in_channels_1=in_channels_1,\n",
    "                    in_channels_2=in_channels_2,\n",
    "                    att=att,\n",
    "                )\n",
    "            )\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.lin_0 = torch.nn.Linear(in_channels_0, num_classes)\n",
    "        self.lin_1 = torch.nn.Linear(in_channels_1, num_classes)\n",
    "        self.lin_2 = torch.nn.Linear(in_channels_2, num_classes)\n",
    "\n",
    "    def forward(self, x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2):\n",
    "        \"\"\"Forward computation through layers, then linear layers, then avg pooling.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_0 : torch.Tensor, shape = [n_nodes, in_channels_0]\n",
    "            Input features on the nodes (0-cells).\n",
    "        x_1 : torch.Tensor, shape = [n_edges, in_channels_1]\n",
    "            Input features on the edges (1-cells).\n",
    "        neighborhood_0_to_0 : tensor, shape = [n_nodes, n_nodes]\n",
    "            Adjacency matrix of rank 0 (up).\n",
    "        neighborhood_1_to_2 : tensor, shape = [n_faces, n_edges]\n",
    "            Transpose of boundary matrix of rank 2.\n",
    "        x_2 : torch.Tensor, shape = [n_faces, in_channels_2]\n",
    "            Input features on the faces (2-cells).\n",
    "            Optional. Use for attention mechanism between edges and faces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _ : tensor, shape = [1]\n",
    "            Label assigned to whole complex.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0, x_1, neighborhood_0_to_0, neighborhood_1_to_2)\n",
    "        x_0 = self.lin_0(x_0)\n",
    "        x_1 = self.lin_1(x_1)\n",
    "        x_2 = self.lin_2(x_2)\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return two_dimensional_cells_mean + one_dimensional_cells_mean + zero_dimensional_cells_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:40.411845803Z",
     "start_time": "2023-05-31T09:19:40.408861921Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CCXN(in_channels_0, in_channels_1, in_channels_2, num_classes=2, n_layers=2)\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:41.150933630Z",
     "start_time": "2023-05-31T09:19:41.146986990Z"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_0_train, x_0_test = train_test_split(x_0_list, test_size=test_size, shuffle=False)\n",
    "x_1_train, x_1_test = train_test_split(x_1_list, test_size=test_size, shuffle=False)\n",
    "incidence_2_t_train, incidence_2_t_test = train_test_split(\n",
    "    incidence_2_t_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "adjacency_0_train, adjacency_0_test = train_test_split(\n",
    "    adjacency_0_list, test_size=test_size, shuffle=False\n",
    ")\n",
    "y_train, y_test = train_test_split(y_list, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the CCXN using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:19:42.918836083Z",
     "start_time": "2023-05-31T09:19:42.114801039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 1.5594 Train_acc: 0.3750\n",
      "Epoch: 2 loss: 0.6690 Train_acc: 0.7500\n",
      "Test_acc: 0.7500\n",
      "Epoch: 3 loss: 0.5635 Train_acc: 0.6875\n",
      "Epoch: 4 loss: 0.6332 Train_acc: 0.7500\n",
      "Test_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "        x_0, x_1, y = x_0.float().to(device), x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "        incidence_2_t, adjacency_0 = incidence_2_t.float().to(device), adjacency_0.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                x_0, x_1, y = x_0.float().to(device), x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "                incidence_2_t, adjacency_0 = incidence_2_t.float().to(device), adjacency_0.float().to(device)\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network with Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new neural network, that uses the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T09:20:01.334080388Z",
     "start_time": "2023-05-31T09:20:01.303035409Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CCXN(\n",
    "    in_channels_0, in_channels_1, in_channels_2, num_classes=2, n_layers=2, att=True\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the training for this neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:02:41.625540Z",
     "start_time": "2023-06-09T15:02:37.301795Z"
    }
   },
   "outputs": [],
   "source": [
    "test_interval = 2\n",
    "for epoch_i in range(1, 5):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "        x_0_train, x_1_train, incidence_2_t_train, adjacency_0_train, y_train\n",
    "    ):\n",
    "        x_0, x_1, y = x_0.float().to(device), x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "        incidence_2_t, adjacency_0 = incidence_2_t.float().to(device), adjacency_0.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, incidence_2_t, adjacency_0, y in zip(\n",
    "                x_0_test, x_1_test, incidence_2_t_test, adjacency_0_test, y_test\n",
    "            ):\n",
    "                x_0, x_1, y = x_0.float().to(device), x_1.float().to(device), torch.tensor(y, dtype=torch.long).to(device)\n",
    "                incidence_2_t, adjacency_0 = incidence_2_t.float().to(device), adjacency_0.float().to(device)\n",
    "                y_hat = model(x_0, x_1, adjacency_0, incidence_2_t)\n",
    "\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
