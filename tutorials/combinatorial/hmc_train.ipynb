{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Combinatorial Complex Attention Neural Network for Mesh Classification.\n",
    "\n",
    "We create and train a combinatorial complex attention neural network for mesh classification, introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The neural network is composed of a sequence of identical attention layers for a dimension two combinatorial complex. Each layer is composed of two levels. In both levels, messages computed for the cells of identical dimension are aggregated using a sum operation. All the messages are computed using the attention mechanisms for squared and non-squared neighborhoods presented in [Definitions 31, 32, and 33, Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). The following message passing scheme is followed in each of the levels for each layer:\n",
    "\n",
    "1. First level:\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 0}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 1}\\right) h_y^{t,(2)} \\Theta^t_{2\\rightarrow 1}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 0}_{x}=\\sum_{y\\in B_{1}(x)} m^{1\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 1}_{x}=\\sum_{y\\in B_{2}(x)} m^{2\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{0\\rightarrow 1}_{x}+m^{2\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(2)} = m_x^{(2)}$\n",
    "\n",
    "where $i_x^{t,(\\cdot)}$ represents intermediate feature vectors.\n",
    "\n",
    "\n",
    "2. Second level:\n",
    "\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 1}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\downarrow, 2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 2}\\right) i_y^{t,(2)} \\Theta^t_{2\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 1}_{x}=\\sum_{y\\in A_{\\uparrow, 1}(x)} m^{1\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 2}_{x}=\\sum_{y\\in A_{\\downarrow, 2}(x)} m^{2\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{1\\rightarrow 1}_{x} + m^{0\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x} + m^{2\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(2)} = m_x^{(2)}$\n",
    "\n",
    "In both message passing levels, $\\phi$ represents a common activation function. Also, $\\Theta$ and $\\text{att}$ represent learnable weights and attention matrices, respectively, that are different in each level. Attention matrices are introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). In this case, attention matrices are computed using the LeakyReLU activation function, as in previous versions of the paper.\n",
    "\n",
    "Notations, adjacency, coadjacency, and incidence matrices are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031). The tensor diagram for the layer can be found in the first column and last row of Figure 11, from the same paper.\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:46:59.404823Z",
     "start_time": "2023-06-28T16:46:59.399153Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:28:28.331854Z",
     "start_time": "2023-06-28T15:28:28.328168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification.\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping the files...\n",
      "\n",
      "done!\n",
      "Loading dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec_training, shrec_testing = shrec_16()\n",
    "\n",
    "# training dataset\n",
    "training_complexes = [\n",
    "    cc.to_combinatorial_complex() for cc in shrec_training[\"complexes\"]\n",
    "]\n",
    "training_labels = shrec_training[\"label\"]\n",
    "training_node_feat = shrec_training[\"node_feat\"]\n",
    "training_edge_feat = shrec_training[\"edge_feat\"]\n",
    "training_face_feat = shrec_training[\"face_feat\"]\n",
    "\n",
    "# testing dataset\n",
    "testing_complexes = [cc.to_combinatorial_complex() for cc in shrec_testing[\"complexes\"]]\n",
    "testing_labels = shrec_testing[\"label\"]\n",
    "testing_node_feat = shrec_testing[\"node_feat\"]\n",
    "testing_edge_feat = shrec_testing[\"edge_feat\"]\n",
    "testing_face_feat = shrec_testing[\"face_feat\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:47:10.373525Z",
     "start_time": "2023-06-28T16:47:09.878944Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "training_complexes[0].incidence_matrix(rank=2,to_rank = None, incidence_type = \"down\").todense()\n",
    "#what is going on with self.skeleton??"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.237625Z",
     "start_time": "2023-06-28T16:04:20.232649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\"\"\"\n",
    "\n",
    "training_node_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.619255Z",
     "start_time": "2023-06-28T16:04:20.617711Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\"\"\"\n",
    "\n",
    "training_edge_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.622296Z",
     "start_time": "2023-06-28T16:04:20.620456Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.567542  ,  0.570995  , -0.210023  , -0.06894332,  0.72564355,\n         0.6846081 ],\n       [ 0.603908  ,  0.557968  , -0.223298  ,  0.91155493,  0.37192256,\n         0.17533174],\n       [ 0.591494  ,  0.464737  ,  0.350567  ,  0.33390166,  0.55019138,\n         0.76537515],\n       ...,\n       [-0.331773  , -0.33001   ,  0.049767  , -0.28529544, -0.95405566,\n        -0.09156586],\n       [-0.401883  , -0.263047  ,  0.136766  , -0.66302596, -0.62547973,\n         0.41130485],\n       [ 0.261249  ,  0.128185  ,  0.304997  ,  0.7728916 , -0.44845904,\n         0.44891321]])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n",
    "\"\"\"\n",
    "\n",
    "training_face_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.625457Z",
     "start_time": "2023-06-28T16:04:20.622655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# training_complexes[0].to_trimesh().show()"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.628301Z",
     "start_time": "2023-06-28T16:04:20.626059Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.633195Z",
     "start_time": "2023-06-28T16:04:20.628801Z"
    }
   },
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Implementing the CCXN architecture will require to perform message passing along neighborhood structures of the cell complexes.\n",
    "\n",
    "Thus, now we retrieve these neighborhood structures (i.e. their representative matrices) that we will use to send messages. \n",
    "\n",
    "For the CCXN, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 6.16026555e-04,  3.42332662e-01,  9.39444198e-01, ...,\n         9.55859971e-01,  4.28478956e-01,  1.75725373e+00],\n       [ 6.81088138e-04,  3.97494225e-01,  1.96188417e-01, ...,\n         4.59912686e-01,  1.33996485e+00,  1.34171512e+00],\n       [ 2.02495554e-03, -7.65949901e-01,  4.13444548e-01, ...,\n         1.32871011e+00,  1.22375172e+00,  5.89130819e-01],\n       ...,\n       [ 1.88118714e-03,  1.16577970e-01, -9.84528932e-01, ...,\n         3.64363423e-01,  1.93855641e+00,  8.38672818e-01],\n       [ 1.50431667e-03, -4.34561991e-01, -8.48251445e-01, ...,\n         1.54860901e+00,  5.77114229e-01,  1.01586942e+00],\n       [ 1.74908308e-03, -8.97968600e-01, -3.36066581e-01, ...,\n         1.04615878e+00,  1.50159627e+00,  5.93837603e-01]])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.633279Z",
     "start_time": "2023-06-28T16:04:20.631251Z"
    }
   },
   "outputs": [],
   "source": [
    "adjacency_0_train_list = []\n",
    "adjacency_1_train_list = []\n",
    "coadjacency_2_train_list = []\n",
    "\n",
    "incidence_1_train_list = []\n",
    "incidence_2_train_list = []\n",
    "\n",
    "for cc in training_complexes:\n",
    "\n",
    "    adjacency_0_train = torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse()\n",
    "    adjacency_1_train = torch.from_numpy(cc.adjacency_matrix(1,2).todense()).to_sparse()\n",
    "    B = cc.incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "    A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "    coadjacency_2_train = torch.from_numpy(A.todense()).to_sparse()\n",
    "\n",
    "    adjacency_0_train_list.append(adjacency_0_train)\n",
    "    adjacency_1_train_list.append(adjacency_1_train)\n",
    "    coadjacency_2_train_list.append(coadjacency_2_train)\n",
    "\n",
    "    incidence_1_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(1, 0).todense()\n",
    "    ).to_sparse()\n",
    "    incidence_2_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(2, 1).todense()\n",
    "    ).to_sparse()\n",
    "\n",
    "    incidence_1_train_list.append(incidence_1_train)\n",
    "    incidence_2_train_list.append(incidence_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Adjacency_1 of the 0-th complex: torch.Size([750, 750]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([500, 500]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n"
     ]
    }
   ],
   "source": [
    "# training_complexes[0].coadjacency_matrix(rank=2,via_rank=1).todense()\n",
    "from scipy.sparse import csr_matrix\n",
    "B = training_complexes[0].incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "print(B.shape)\n",
    "A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "print(A.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T15:28:57.485721Z",
     "start_time": "2023-06-28T15:28:57.479137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_train_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_train_list[i_cc].shape}.\")\n",
    "print(\n",
    "    f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_train_list[i_cc].shape}.\"\n",
    ")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_train_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_train_list[i_cc].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:47.878013Z",
     "start_time": "2023-06-28T16:04:20.634524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 500)\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "adjacency_0_test_list = []\n",
    "adjacency_1_test_list = []\n",
    "coadjacency_2_test_list = []\n",
    "incidence_1_test_list = []\n",
    "incidence_2_test_list = []\n",
    "\n",
    "for cc in testing_complexes:\n",
    "\n",
    "    adjacency_0_test = torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse()\n",
    "    adjacency_1_test = torch.from_numpy(cc.adjacency_matrix(1,2).todense()).to_sparse()\n",
    "    B = cc.incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "    A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "    coadjacency_2_test = torch.from_numpy(A.todense()).to_sparse()\n",
    "    #torch.from_numpy(cc.coadjacency_matrix(2,1).todense()).to_sparse()\n",
    "\n",
    "    adjacency_0_test_list.append(adjacency_0_test)\n",
    "    adjacency_1_test_list.append(adjacency_1_test)\n",
    "    coadjacency_2_test_list.append(coadjacency_2_test)\n",
    "\n",
    "    incidence_1_test = torch.from_numpy(cc.incidence_matrix(1, 0).todense()).to_sparse()\n",
    "    incidence_2_test = torch.from_numpy(cc.incidence_matrix(2, 1).todense()).to_sparse()\n",
    "\n",
    "    incidence_1_test_list.append(incidence_1_test)\n",
    "    incidence_2_test_list.append(incidence_2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:47.899607Z",
     "start_time": "2023-06-28T16:04:47.878317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Adjacency_1 of the 0-th complex: torch.Size([750, 750]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([500, 500]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n"
     ]
    }
   ],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_test_list[i_cc].shape}.\")\n",
    "print(f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_test_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_test_list[i_cc].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:47.917014Z",
     "start_time": "2023-06-28T16:04:47.898092Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:29:08.429219Z",
     "start_time": "2023-06-28T15:29:08.424668Z"
    }
   },
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 7.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:26.773790Z",
     "start_time": "2023-06-28T15:39:26.764586Z"
    }
   },
   "outputs": [],
   "source": [
    "d_0 = training_node_feat[0].shape[-1]\n",
    "d_1 = training_edge_feat[0].shape[-1]\n",
    "d_2 = training_face_feat[0].shape[-1]\n",
    "\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.layer = HMCLayer(\n",
    "            in_channels=in_channels,\n",
    "            intermediate_channels=intermediate_channels,\n",
    "            out_channels=out_channels,\n",
    "            negative_slope=negative_slope,\n",
    "        )\n",
    "        \"\"\"self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope\n",
    "            ) for _ in range(n_layers)\n",
    "        )\"\"\"\n",
    "\n",
    "        self.l0 = torch.nn.Linear(out_channels[0], num_classes)\n",
    "        self.l1 = torch.nn.Linear(out_channels[1], num_classes)\n",
    "        self.l2 = torch.nn.Linear(out_channels[2], num_classes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        x_0, x_1, x_2 = self.layer(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            neighborhood_0_to_0,\n",
    "            neighborhood_1_to_1,\n",
    "            neighborhood_2_to_2,\n",
    "            neighborhood_0_to_1,\n",
    "            neighborhood_1_to_2,\n",
    "        )\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2\n",
    "                                  )\"\"\"\n",
    "\n",
    "        x_0 = self.l0(x_0)\n",
    "        x_1 = self.l1(x_1)\n",
    "        x_2 = self.l2(x_2)\n",
    "\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:42.299Z",
     "start_time": "2023-06-28T15:39:42.293858Z"
    }
   },
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.unique(training_labels).shape[0]\n",
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=num_classes,\n",
    "    n_layers=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:23.697609Z",
     "start_time": "2023-06-28T15:38:23.505866Z"
    }
   },
   "source": [
    "We train the HoanMeshClassifier using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 1728.3707 Train_acc: 0.0100\n",
      "Epoch: 2 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 3 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 4 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 5 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 6 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 7 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 8 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 9 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 10 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 11 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 12 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 13 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 14 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 15 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 16 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 17 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 18 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 19 loss: 3.4012 Train_acc: 0.0100\n",
      "Epoch: 20 loss: 3.4012 Train_acc: 0.0100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m incidence_1, incidence_2 \u001B[38;5;241m=\u001B[39m incidence_1\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device), incidence_2\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     15\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 16\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency_0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoadjacency_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincidence_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mincidence_2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m crit(y_hat, y)\n\u001B[1;32m     18\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (y_hat\u001B[38;5;241m.\u001B[39margmax() \u001B[38;5;241m==\u001B[39m y)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[32], line 64\u001B[0m, in \u001B[0;36mHoanMeshClassifier.forward\u001B[0;34m(self, x_0, x_1, x_2, neighborhood_0_to_0, neighborhood_1_to_1, neighborhood_2_to_2, neighborhood_0_to_1, neighborhood_1_to_2)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     51\u001B[0m         x_0,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     58\u001B[0m         neighborhood_1_to_2,\n\u001B[1;32m     59\u001B[0m         ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 64\u001B[0m         x_0, x_1, x_2 \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mneighborhood_0_to_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mneighborhood_1_to_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mneighborhood_2_to_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mneighborhood_0_to_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mneighborhood_1_to_2\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m                              \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m     x_0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml0(x_0)\n\u001B[1;32m     75\u001B[0m     x_1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1(x_1)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/nn/combinatorial/hmc_layer.py:175\u001B[0m, in \u001B[0;36mHMCLayer.forward\u001B[0;34m(self, x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;66;03m# Computing messages from Higher Order Attention Blocks Level 2\u001B[39;00m\n\u001B[1;32m    174\u001B[0m x_0_to_0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhbs_0_level2(x_0_level1, adjacency_0)\n\u001B[0;32m--> 175\u001B[0m x_1_to_1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhbs_1_level2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_1_level1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madjacency_1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m x_2_to_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhbs_2_level2(x_2_level1, coadjacency_2)\n\u001B[1;32m    178\u001B[0m x_0_to_1, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhbns_0_1_level2(x_1_level1, x_0_level1, incidence_1)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:203\u001B[0m, in \u001B[0;36mHBS.forward\u001B[0;34m(self, x_source, neighborhood)\u001B[0m\n\u001B[1;32m    197\u001B[0m neighborhood \u001B[38;5;241m=\u001B[39m [result \u001B[38;5;241m:=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39mmm(neighborhood, result) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm_hop)]\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# TODO: parallelize?\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;66;03m# with Pool() as pool:\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# att_p = pool.map(self.attention, message)\u001B[39;00m\n\u001B[0;32m--> 203\u001B[0m att \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(m_p, A_p, a_p) \u001B[38;5;28;01mfor\u001B[39;00m m_p, A_p, a_p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(message, neighborhood, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matt_weight)]\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msparse_hadamard\u001B[39m(A_p, att_p):\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39msparse_coo_tensor(\n\u001B[1;32m    207\u001B[0m         indices\u001B[38;5;241m=\u001B[39mA_p\u001B[38;5;241m.\u001B[39mindices(),\n\u001B[1;32m    208\u001B[0m         values\u001B[38;5;241m=\u001B[39matt_p\u001B[38;5;241m.\u001B[39mvalues() \u001B[38;5;241m*\u001B[39m A_p\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m    209\u001B[0m         size\u001B[38;5;241m=\u001B[39mA_p\u001B[38;5;241m.\u001B[39mshape,\n\u001B[1;32m    210\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:203\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    197\u001B[0m neighborhood \u001B[38;5;241m=\u001B[39m [result \u001B[38;5;241m:=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39mmm(neighborhood, result) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm_hop)]\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# TODO: parallelize?\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;66;03m# with Pool() as pool:\u001B[39;00m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# att_p = pool.map(self.attention, message)\u001B[39;00m\n\u001B[0;32m--> 203\u001B[0m att \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma_p\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m m_p, A_p, a_p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(message, neighborhood, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matt_weight)]\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msparse_hadamard\u001B[39m(A_p, att_p):\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39msparse_coo_tensor(\n\u001B[1;32m    207\u001B[0m         indices\u001B[38;5;241m=\u001B[39mA_p\u001B[38;5;241m.\u001B[39mindices(),\n\u001B[1;32m    208\u001B[0m         values\u001B[38;5;241m=\u001B[39matt_p\u001B[38;5;241m.\u001B[39mvalues() \u001B[38;5;241m*\u001B[39m A_p\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m    209\u001B[0m         size\u001B[38;5;241m=\u001B[39mA_p\u001B[38;5;241m.\u001B[39mshape,\n\u001B[1;32m    210\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:172\u001B[0m, in \u001B[0;36mHBS.attention\u001B[0;34m(self, message, A_p, a_p)\u001B[0m\n\u001B[1;32m    165\u001B[0m s_to_s \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([message[source_index_i], message[source_index_j]], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    166\u001B[0m e_p \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse_coo_tensor(\n\u001B[1;32m    167\u001B[0m     indices\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor([source_index_i\u001B[38;5;241m.\u001B[39mtolist(), source_index_j\u001B[38;5;241m.\u001B[39mtolist()]),\n\u001B[1;32m    168\u001B[0m     values\u001B[38;5;241m=\u001B[39mF\u001B[38;5;241m.\u001B[39mleaky_relu(torch\u001B[38;5;241m.\u001B[39mmatmul(s_to_s, a_p),\n\u001B[1;32m    169\u001B[0m                         negative_slope\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnegative_slope)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m),\n\u001B[1;32m    170\u001B[0m     size\u001B[38;5;241m=\u001B[39m(n_messages, n_messages)\n\u001B[1;32m    171\u001B[0m )\n\u001B[0;32m--> 172\u001B[0m att_p \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse\u001B[38;5;241m.\u001B[39msoftmax(e_p, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax \u001B[38;5;28;01melse\u001B[39;00m \u001B[43msparse_row_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[43me_p\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m att_p\n",
      "File \u001B[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:29\u001B[0m, in \u001B[0;36msparse_row_norm\u001B[0;34m(sparse_tensor)\u001B[0m\n\u001B[1;32m     27\u001B[0m values \u001B[38;5;241m=\u001B[39m sparse_tensor\u001B[38;5;241m.\u001B[39m_values() \u001B[38;5;241m/\u001B[39m row_sum\u001B[38;5;241m.\u001B[39mto_dense()[sparse_tensor\u001B[38;5;241m.\u001B[39m_indices()[\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m     28\u001B[0m sparse_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse_coo_tensor(sparse_tensor\u001B[38;5;241m.\u001B[39m_indices(), values, sparse_tensor\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msparse_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoalesce\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interval = 25\n",
    "num_epochs = 500\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for (\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        adjacency_0,\n",
    "        adjacency_1,\n",
    "        coadjacency_2,\n",
    "        incidence_1,\n",
    "        incidence_2,\n",
    "        y,\n",
    "    ) in zip(\n",
    "        training_node_feat,\n",
    "        training_edge_feat,\n",
    "        training_face_feat,\n",
    "        adjacency_0_train_list,\n",
    "        adjacency_1_train_list,\n",
    "        coadjacency_2_train_list,\n",
    "        incidence_1_train_list,\n",
    "        incidence_2_train_list,\n",
    "        training_labels,\n",
    "    ):\n",
    "        x_0, x_1, x_2 = (\n",
    "            torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "        )\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "            adjacency_0.float().to(device),\n",
    "            adjacency_1.float().to(device),\n",
    "            coadjacency_2.float().to(device),\n",
    "        )\n",
    "        incidence_1, incidence_2 = incidence_1.float().to(\n",
    "            device\n",
    "        ), incidence_2.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model.forward(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            adjacency_0,\n",
    "            adjacency_1,\n",
    "            coadjacency_2,\n",
    "            incidence_1,\n",
    "            incidence_2,\n",
    "        )\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2, y in zip(\n",
    "                testing_node_feat, testing_edge_feat, testing_face_feat, adjacency_0_test_list, adjacency_1_test_list, coadjacency_2_test_list, incidence_1_test_list, incidence_2_test_list, testing_labels\n",
    "            ):\n",
    "                x_0, x_1, x_2 = (\n",
    "                    torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "                )\n",
    "                y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "                adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "                    adjacency_0.float().to(device),\n",
    "                    adjacency_1.float().to(device),\n",
    "                    coadjacency_2.float().to(device),\n",
    "                )\n",
    "                incidence_1, incidence_2 = incidence_1.float().to(\n",
    "                    device\n",
    "                ), incidence_2.float().to(device)\n",
    "                opt.zero_grad()\n",
    "                y_hat = model.forward(x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2)\n",
    "                loss = crit(y_hat, y)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
