{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Combinatorial Complex Attention Neural Network for Mesh Classification.\n",
    "\n",
    "We create and train a combinatorial complex attention neural network for mesh classification, introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The neural network is composed of a sequence of identical attention layers for a dimension two combinatorial complex. Each layer is composed of two levels. In both levels, messages computed for the cells of identical dimension are aggregated using a sum operation. All the messages are computed using the attention mechanisms for squared and non-squared neighborhoods presented in [Definitions 31, 32, and 33, Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). The following message passing scheme is followed in each of the levels for each layer:\n",
    "\n",
    "1. First level:\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 0}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 1}\\right) h_y^{t,(2)} \\Theta^t_{2\\rightarrow 1}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 0}_{x}=\\sum_{y\\in B_{1}(x)} m^{1\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 1}_{x}=\\sum_{y\\in B_{2}(x)} m^{2\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{0\\rightarrow 1}_{x}+m^{2\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(2)} = m_x^{(2)}$\n",
    "\n",
    "where $i_x^{t,(\\cdot)}$ represents intermediate feature vectors.\n",
    "\n",
    "\n",
    "2. Second level:\n",
    "\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 1}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\downarrow, 2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 2}\\right) i_y^{t,(2)} \\Theta^t_{2\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 1}_{x}=\\sum_{y\\in A_{\\uparrow, 1}(x)} m^{1\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 2}_{x}=\\sum_{y\\in A_{\\downarrow, 2}(x)} m^{2\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{1\\rightarrow 1}_{x} + m^{0\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x} + m^{2\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(2)} = m_x^{(2)}$\n",
    "\n",
    "In both message passing levels, $\\phi$ represents a common activation function. Also, $\\Theta$ and $\\text{att}$ represent learnable weights and attention matrices, respectively, that are different in each level. Attention matrices are introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). In this case, attention matrices are computed using the LeakyReLU activation function, as in previous versions of the paper.\n",
    "\n",
    "Notations, adjacency, coadjacency, and incidence matrices are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031). The tensor diagram for the layer can be found in the first column and last row of Figure 11, from the same paper.\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T11:21:45.088660392Z",
     "start_time": "2023-06-30T11:21:45.088338424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:21:46.745693914Z",
     "start_time": "2023-06-30T11:21:45.088512538Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:21:46.779586513Z",
     "start_time": "2023-06-30T11:21:46.747209677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification.\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:21:47.393226082Z",
     "start_time": "2023-06-30T11:21:46.778960806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping the files...\n",
      "\n",
      "done!\n",
      "Loading dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec_training, shrec_testing = shrec_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:21:47.417035500Z",
     "start_time": "2023-06-30T11:21:47.397564197Z"
    }
   },
   "outputs": [],
   "source": [
    "class SHRECDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.complexes = [cc.to_combinatorial_complex() for cc in data[\"complexes\"]]\n",
    "        self.x_0 = data[\"node_feat\"]\n",
    "        self.x_1 = data[\"edge_feat\"]\n",
    "        self.x_2 = data[\"face_feat\"]\n",
    "        self.y = data[\"label\"]\n",
    "        self.a0, self.a1, self.coa2, self.b1, self.b2 = self._get_neighborhood_matrix()\n",
    "\n",
    "    def _get_neighborhood_matrix(self):\n",
    "\n",
    "        a0 = []\n",
    "        a1 = []\n",
    "        coa2 = []\n",
    "        b1 = []\n",
    "        b2 = []\n",
    "\n",
    "        for cc in self.complexes:\n",
    "\n",
    "            a0.append(torch.from_numpy(cc.adjacency_matrix(0, 1).todense()).to_sparse())\n",
    "            a1.append(torch.from_numpy(cc.adjacency_matrix(1, 2).todense()).to_sparse())\n",
    "\n",
    "            B = cc.incidence_matrix(rank=2, to_rank=1)\n",
    "            A = B.T @ B\n",
    "            A.setdiag(0)\n",
    "            coa2.append(torch.from_numpy(A.todense()).to_sparse())\n",
    "\n",
    "            b1.append(torch.from_numpy(cc.incidence_matrix(1, 0).todense()).to_sparse())\n",
    "            b2.append(torch.from_numpy(cc.incidence_matrix(2, 1).todense()).to_sparse())\n",
    "\n",
    "        return a0, a1, coa2, b1, b2\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(np.unique(self.y))\n",
    "\n",
    "    def channels_dim(self):\n",
    "        return self.x_0[0].shape[1], self.x_1[0].shape[1], self.x_2[0].shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.complexes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_0[idx],\n",
    "            self.x_1[idx],\n",
    "            self.x_2[idx],\n",
    "            self.a0[idx],\n",
    "            self.a1[idx],\n",
    "            self.coa2[idx],\n",
    "            self.b1[idx],\n",
    "            self.b2[idx],\n",
    "            self.y[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:22:44.904622412Z",
     "start_time": "2023-06-30T11:21:47.416812636Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = SHRECDataset(shrec_training)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:23:48.838331718Z",
     "start_time": "2023-06-30T11:22:44.904362812Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_dataset = SHRECDataset(shrec_training)\n",
    "testing_dataloader = DataLoader(training_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:12:40.935701Z",
     "start_time": "2023-06-29T09:12:40.933077Z"
    }
   },
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:23:48.881116679Z",
     "start_time": "2023-06-30T11:23:48.880493347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 7.\n"
     ]
    }
   ],
   "source": [
    "d_0, d_1, d_2 = training_dataset.channels_dim()\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:23:48.881301409Z",
     "start_time": "2023-06-30T11:23:48.880749524Z"
    }
   },
   "outputs": [],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "        n_linear_layers=1,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope,\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        )\n",
    "        self.linear_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(\n",
    "                    out_channels[0] + out_channels[1] + out_channels[2],\n",
    "                    out_channels[0] + out_channels[1] + out_channels[2],\n",
    "                )\n",
    "                for _ in range(n_linear_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.final_layer = torch.nn.Linear(\n",
    "            out_channels[0] + out_channels[1] + out_channels[2], num_classes\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2,\n",
    "            )\n",
    "\n",
    "        x = torch.cat([x_0, x_1, x_2], dim=1)\n",
    "        for layer in self.linear_layers:\n",
    "            x = layer(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:11.467775Z",
     "start_time": "2023-06-29T10:21:11.463344Z"
    }
   },
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:23:49.791102441Z",
     "start_time": "2023-06-30T11:23:48.881043346Z"
    }
   },
   "outputs": [],
   "source": [
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=training_dataset.num_classes(),\n",
    "    n_layers=5,\n",
    "    n_linear_layers=10,\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:23.697609Z",
     "start_time": "2023-06-28T15:38:23.505866Z"
    }
   },
   "source": [
    "We train the HoanMeshClassifier using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T11:32:26.919391452Z",
     "start_time": "2023-06-30T11:32:19.261481288Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 252 but got size 750 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 123\u001B[0m\n\u001B[1;32m    120\u001B[0m incidence_2 \u001B[38;5;241m=\u001B[39m incidence_2[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    122\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 123\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43madjacency_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43madjacency_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoadjacency_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mincidence_1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m    \u001B[49m\u001B[43mincidence_2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m loss \u001B[38;5;241m=\u001B[39m crit(y_hat, y)\n\u001B[1;32m    134\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (y_hat\u001B[38;5;241m.\u001B[39margmax() \u001B[38;5;241m==\u001B[39m y)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[15], line 68\u001B[0m, in \u001B[0;36mHoanMeshClassifier.forward\u001B[0;34m(self, x_0, x_1, x_2, neighborhood_0_to_0, neighborhood_1_to_1, neighborhood_2_to_2, neighborhood_0_to_1, neighborhood_1_to_2)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m     58\u001B[0m     x_0, x_1, x_2 \u001B[38;5;241m=\u001B[39m layer(x_0,\n\u001B[1;32m     59\u001B[0m         x_1,\n\u001B[1;32m     60\u001B[0m         x_2,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m         neighborhood_1_to_2\n\u001B[1;32m     66\u001B[0m                           )\n\u001B[0;32m---> 68\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_layers:\n\u001B[1;32m     70\u001B[0m     x \u001B[38;5;241m=\u001B[39m layer(x)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 252 but got size 750 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "        n_linear_layers=1,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope,\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        )\n",
    "        self.linear_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(\n",
    "                    out_channels[0] + out_channels[1] + out_channels[2],\n",
    "                    out_channels[0] + out_channels[1] + out_channels[2],\n",
    "                )\n",
    "                for _ in range(n_linear_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.final_layer = torch.nn.Linear(\n",
    "            out_channels[0] + out_channels[1] + out_channels[2], num_classes\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2,\n",
    "            )\n",
    "\n",
    "        x = torch.cat([x_0, x_1, x_2], dim=1)\n",
    "        for layer in self.linear_layers:\n",
    "            x = layer(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=training_dataset.num_classes(),\n",
    "    n_layers=5,\n",
    "    n_linear_layers=10,\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "test_interval = 25\n",
    "num_epochs = 500\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for (\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        adjacency_0,\n",
    "        adjacency_1,\n",
    "        coadjacency_2,\n",
    "        incidence_1,\n",
    "        incidence_2,\n",
    "        y,\n",
    "    ) in training_dataloader:\n",
    "        x_0, x_1, x_2 = (\n",
    "            x_0[0].float().to(device),\n",
    "            x_1[0].float().to(device),\n",
    "            x_2[0].float().to(device),\n",
    "        )\n",
    "\n",
    "        y = y[0].long().to(device)\n",
    "\n",
    "        adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "            adjacency_0[0].float().to(device),\n",
    "            adjacency_1[0].float().to(device),\n",
    "            coadjacency_2[0].float().to(device),\n",
    "        )\n",
    "\n",
    "        incidence_1 = incidence_1[0].float().to(device)\n",
    "        incidence_2 = incidence_2[0].float().to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        y_hat = model.forward(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            adjacency_0,\n",
    "            adjacency_1,\n",
    "            coadjacency_2,\n",
    "            incidence_1,\n",
    "            incidence_2,\n",
    "        )\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for (\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                adjacency_0,\n",
    "                adjacency_1,\n",
    "                coadjacency_2,\n",
    "                incidence_1,\n",
    "                incidence_2,\n",
    "                y,\n",
    "            ) in testing_dataloader:\n",
    "\n",
    "                x_0, x_1, x_2 = (\n",
    "                    x_0[0].float().to(device),\n",
    "                    x_1[0].float().to(device),\n",
    "                    x_2[0].float().to(device),\n",
    "                )\n",
    "\n",
    "                y = y[0].long().to(device)\n",
    "\n",
    "                adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "                    adjacency_0[0].float().to(device),\n",
    "                    adjacency_1[0].float().to(device),\n",
    "                    coadjacency_2[0].float().to(device),\n",
    "                )\n",
    "\n",
    "                incidence_1 = incidence_1[0].float().to(device)\n",
    "                incidence_2 = incidence_2[0].float().to(device)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                y_hat = model.forward(\n",
    "                    x_0,\n",
    "                    x_1,\n",
    "                    x_2,\n",
    "                    adjacency_0,\n",
    "                    adjacency_1,\n",
    "                    coadjacency_2,\n",
    "                    incidence_1,\n",
    "                    incidence_2,\n",
    "                )\n",
    "                loss = crit(y_hat, y)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
