{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Combinatorial Complex Attention Neural Network for Mesh Classification.\n",
    "\n",
    "We create and train a combinatorial complex attention neural network for mesh classification, introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The neural network is composed of a sequence of identical attention layers for a dimension two combinatorial complex. Each layer is composed of two levels. In both levels, messages computed for the cells of identical dimension are aggregated using a sum operation. All the messages are computed using the attention mechanisms for squared and non-squared neighborhoods presented in [Definitions 31, 32, and 33, Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). The following message passing scheme is followed in each of the levels for each layer:\n",
    "\n",
    "1. First level:\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 0}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 1}\\right) h_y^{t,(2)} \\Theta^t_{2\\rightarrow 1}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 0}_{x}=\\sum_{y\\in B_{1}(x)} m^{1\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 1}_{x}=\\sum_{y\\in B_{2}(x)} m^{2\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{0\\rightarrow 1}_{x}+m^{2\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(2)} = m_x^{(2)}$\n",
    "\n",
    "where $i_x^{t,(\\cdot)}$ represents intermediate feature vectors.\n",
    "\n",
    "\n",
    "2. Second level:\n",
    "\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 1}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\downarrow, 2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 2}\\right) i_y^{t,(2)} \\Theta^t_{2\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 1}_{x}=\\sum_{y\\in A_{\\uparrow, 1}(x)} m^{1\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 2}_{x}=\\sum_{y\\in A_{\\downarrow, 2}(x)} m^{2\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{1\\rightarrow 1}_{x} + m^{0\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x} + m^{2\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(2)} = m_x^{(2)}$\n",
    "\n",
    "In both message passing levels, $\\phi$ represents a common activation function. Also, $\\Theta$ and $\\text{att}$ represent learnable weights and attention matrices, respectively, that are different in each level. Attention matrices are introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). In this case, attention matrices are computed using the LeakyReLU activation function, as in previous versions of the paper.\n",
    "\n",
    "Notations, adjacency, coadjacency, and incidence matrices are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031). The tensor diagram for the layer can be found in the first column and last row of Figure 11, from the same paper.\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'topomodelx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m csr_matrix\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtopomodelx\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcombinatorial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhmc_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m HMCLayer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'topomodelx'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T15:59:18.788822Z",
     "start_time": "2023-06-29T15:59:18.784128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification.\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T15:59:19.583002Z",
     "start_time": "2023-06-29T15:59:19.578653Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading shrec 16 full dataset...\n",
      "\n",
      "done!\n",
      "Loading shrec 16 full dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec_training, shrec_testing = shrec_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHRECDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.complexes = [cc.to_combinatorial_complex() for cc in data[\"complexes\"]]\n",
    "        self.x_0 = data[\"node_feat\"]\n",
    "        self.x_1 = data[\"edge_feat\"]\n",
    "        self.x_2 = data[\"face_feat\"]\n",
    "        self.y = data[\"label\"]\n",
    "        self.a0, self.a1, self.coa2, self.b1, self.b2 = self._get_neighborhood_matrix()\n",
    "\n",
    "    def _get_neighborhood_matrix(self):\n",
    "        \n",
    "        a0 = []\n",
    "        a1 = []\n",
    "        coa2 = []\n",
    "        b1 = []\n",
    "        b2 = []\n",
    "        \n",
    "        for cc in self.complexes:\n",
    "\n",
    "            a0.append(torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse())\n",
    "            a1.append(torch.from_numpy(cc.adjacency_matrix(1,2).todense()).to_sparse())\n",
    "            \n",
    "            B = cc.incidence_matrix(rank=2,to_rank=1)\n",
    "            A = B.T @ B\n",
    "            A.setdiag(0)\n",
    "            coa2.append(torch.from_numpy(A.todense()).to_sparse())\n",
    "            \n",
    "            b1.append(torch.from_numpy(cc.incidence_matrix(1,0).todense()).to_sparse())\n",
    "            b2.append(torch.from_numpy(cc.incidence_matrix(2,1).todense()).to_sparse())\n",
    "            \n",
    "        return a0, a1, coa2, b1, b2\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(np.unique(self.y))\n",
    "    \n",
    "    def channels_dim(self):\n",
    "        return self.x_0[0].shape[1], self.x_1[0].shape[1], self.x_2[0].shape[1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.complexes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_0[idx], self.x_1[idx], self.x_2[idx], self.y[idx], self.a0[idx], self.a1[idx], self.coa2[idx], self.b1[idx], self.b2[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T15:59:23.256887Z",
     "start_time": "2023-06-29T15:59:23.224105Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading dataset...\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shrec_training, shrec_testing \u001b[38;5;241m=\u001b[39m \u001b[43mshrec_16\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/TopoNetX/toponetx/datasets/mesh.py:97\u001b[0m, in \u001b[0;36mshrec_16\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshrec_16\u001b[39m(size: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load training/testing shrec 16 datasets.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    size : {'full', 'small'}, default='full'\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m        Dataset size. Options are \"full\" or \"small\".\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    tuple of length 2 npz files\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        The npz files store the training/testing complexes of shrec 16 dataset along\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m        with their nodes, edges and faces features.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Each npz file stores 5 keys:\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;124;03m    \"complexes\",\"node_feat\",\"edge_feat\", \"face_feat\" and mesh label\".\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    complex : stores the simplicial complex of the mesh\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    node_feat : stores a 6 dim node feature vector: position and normal of the each node in the mesh\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    edge_feat : stores a 10 dim edge feature vector: diheral angle, edge span, 2 edge angle in the triangle, 6 edge ratios.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    face_feat : stores a 7-dimensional face feature vector: face area (1 feat), face normal (3 feat), face angles (3 feat)\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    mesh label : stores the label of the mesh\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    Raises\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    ------\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    RuntimeError\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m        If dataset is not found on in DIR.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    >>> shrec_training, shrec_testing = shrec_16()\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    >>> # training dataset\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    >>> training_complexes = shrec_training[\"complexes\"]\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    >>> training_labels = shrec_training[\"label\"]\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    >>> training_node_feat = shrec_training[\"node_feat\"]\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    >>> training_edge_feat = shrec_training[\"edge_feat\"]\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    >>> training_face_feat = shrec_training[\"face_feat\"]\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    >>> # testing dataset\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    >>> testing_complexes = shrec_testing[\"complexes\"]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    >>> testing_labels = shrec_testing[\"label\"]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    >>> testing_node_feat = shrec_testing[\"node_feat\"]\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    >>> testing_edge_feat = shrec_testing[\"edge_feat\"]\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    >>> testing_face_feat = shrec_testing[\"face_feat\"]\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SHREC_DS_MAP:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/wget.py:506\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# get filename for temp file in current directory\u001b[39;00m\n\u001b[1;32m    505\u001b[0m prefix \u001b[38;5;241m=\u001b[39m detect_filename(url, out)\n\u001b[0;32m--> 506\u001b[0m (fd, tmpfile) \u001b[38;5;241m=\u001b[39m \u001b[43mtempfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkstemp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.tmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m os\u001b[38;5;241m.\u001b[39mclose(fd)\n\u001b[1;32m    508\u001b[0m os\u001b[38;5;241m.\u001b[39munlink(tmpfile)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/tempfile.py:341\u001b[0m, in \u001b[0;36mmkstemp\u001b[0;34m(suffix, prefix, dir, text)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     flags \u001b[38;5;241m=\u001b[39m _bin_openflags\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_mkstemp_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/tempfile.py:246\u001b[0m, in \u001b[0;36m_mkstemp_inner\u001b[0;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mkstemp_inner\u001b[39m(\u001b[38;5;28mdir\u001b[39m, pre, suf, flags, output_type):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Code common to mkstemp, TemporaryFile, and NamedTemporaryFile.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_os\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     names \u001b[38;5;241m=\u001b[39m _get_candidate_names()\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/posixpath.py:384\u001b[0m, in \u001b[0;36mabspath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    382\u001b[0m         cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwdb()\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m         cwd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     path \u001b[38;5;241m=\u001b[39m join(cwd, path)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normpath(path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T15:56:39.965Z",
     "start_time": "2023-06-29T15:56:39.951306Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.567542  ,  0.570995  , -0.210023  , -0.06894332,  0.72564355,\n",
       "         0.6846081 ],\n",
       "       [ 0.603908  ,  0.557968  , -0.223298  ,  0.91155493,  0.37192256,\n",
       "         0.17533174],\n",
       "       [ 0.591494  ,  0.464737  ,  0.350567  ,  0.33390166,  0.55019138,\n",
       "         0.76537515],\n",
       "       ...,\n",
       "       [-0.331773  , -0.33001   ,  0.049767  , -0.28529544, -0.95405566,\n",
       "        -0.09156586],\n",
       "       [-0.401883  , -0.263047  ,  0.136766  , -0.66302596, -0.62547973,\n",
       "         0.41130485],\n",
       "       [ 0.261249  ,  0.128185  ,  0.304997  ,  0.7728916 , -0.44845904,\n",
       "         0.44891321]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\"\"\"\n",
    "\n",
    "training_node_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:25:39.734232Z",
     "start_time": "2023-06-29T09:24:00.017360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\"\"\"\n",
    "\n",
    "training_edge_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T07:51:21.207631Z",
     "start_time": "2023-06-29T07:51:21.192331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[  0,   0,   0,  ..., 499, 499, 499],\n",
      "                       [  1,   2,   4,  ..., 465, 478, 495]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(500, 500), nnz=1500, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n",
    "\"\"\"\n",
    "\n",
    "training_face_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.628301Z",
     "start_time": "2023-06-28T16:04:20.626059Z"
    }
   },
   "outputs": [],
   "source": [
    "# training_complexes[0].to_trimesh().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.633195Z",
     "start_time": "2023-06-28T16:04:20.628801Z"
    }
   },
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Implementing the CCXN architecture will require to perform message passing along neighborhood structures of the cell complexes.\n",
    "\n",
    "Thus, now we retrieve these neighborhood structures (i.e. their representative matrices) that we will use to send messages. \n",
    "\n",
    "For the CCXN, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:20.633279Z",
     "start_time": "2023-06-28T16:04:20.631251Z"
    }
   },
   "outputs": [],
   "source": [
    "adjacency_0_train_list = []\n",
    "adjacency_1_train_list = []\n",
    "coadjacency_2_train_list = []\n",
    "\n",
    "incidence_1_train_list = []\n",
    "incidence_2_train_list = []\n",
    "\n",
    "for cc in training_complexes:\n",
    "\n",
    "    adjacency_0_train = torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse()\n",
    "    adjacency_1_train = torch.from_numpy(cc.adjacency_matrix(1,2).todense()).to_sparse()\n",
    "    B = cc.incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "    A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "    coadjacency_2_train = torch.from_numpy(A.todense()).to_sparse()\n",
    "\n",
    "    adjacency_0_train_list.append(adjacency_0_train)\n",
    "    adjacency_1_train_list.append(adjacency_1_train)\n",
    "    coadjacency_2_train_list.append(coadjacency_2_train)\n",
    "\n",
    "    incidence_1_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(1, 0).todense()\n",
    "    ).to_sparse()\n",
    "    incidence_2_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(2, 1).todense()\n",
    "    ).to_sparse()\n",
    "\n",
    "    incidence_1_train_list.append(incidence_1_train)\n",
    "    incidence_2_train_list.append(incidence_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:28:57.485721Z",
     "start_time": "2023-06-28T15:28:57.479137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Adjacency_1 of the 0-th complex: torch.Size([750, 750]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([500, 500]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n"
     ]
    }
   ],
   "source": [
    "# training_complexes[0].coadjacency_matrix(rank=2,via_rank=1).todense()\n",
    "from scipy.sparse import csr_matrix\n",
    "B = training_complexes[0].incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "print(B.shape)\n",
    "A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "print(A.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T16:04:47.878013Z",
     "start_time": "2023-06-28T16:04:20.634524Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_train_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_train_list[i_cc].shape}.\")\n",
    "print(\n",
    "    f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_train_list[i_cc].shape}.\"\n",
    ")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_train_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_train_list[i_cc].shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:28:49.877605Z",
     "start_time": "2023-06-29T08:28:49.871450Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 7.\n"
     ]
    }
   ],
   "source": [
    "adjacency_0_test_list = []\n",
    "adjacency_1_test_list = []\n",
    "coadjacency_2_test_list = []\n",
    "incidence_1_test_list = []\n",
    "incidence_2_test_list = []\n",
    "\n",
    "for cc in testing_complexes:\n",
    "\n",
    "    adjacency_0_test = torch.from_numpy(cc.adjacency_matrix(0,1).todense()).to_sparse()\n",
    "    adjacency_1_test = torch.from_numpy(cc.adjacency_matrix(1,2).todense()).to_sparse()\n",
    "    B = cc.incidence_matrix(rank=2,to_rank=1,incidence_type=\"down\", sparse=True)\n",
    "    A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "    coadjacency_2_test = torch.from_numpy(A.todense()).to_sparse()\n",
    "    #torch.from_numpy(cc.coadjacency_matrix(2,1).todense()).to_sparse()\n",
    "\n",
    "    adjacency_0_test_list.append(adjacency_0_test)\n",
    "    adjacency_1_test_list.append(adjacency_1_test)\n",
    "    coadjacency_2_test_list.append(coadjacency_2_test)\n",
    "\n",
    "    incidence_1_test = torch.from_numpy(cc.incidence_matrix(1, 0).todense()).to_sparse()\n",
    "    incidence_2_test = torch.from_numpy(cc.incidence_matrix(2, 1).todense()).to_sparse()\n",
    "\n",
    "    incidence_1_test_list.append(incidence_1_test)\n",
    "    incidence_2_test_list.append(incidence_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:20:58.279556Z",
     "start_time": "2023-06-29T09:20:58.273056Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8908,  0.0882, -0.1654,  0.8797,  0.4745,  0.0311],\n",
      "        [ 0.8642,  0.0510, -0.2256,  0.3513, -0.1276, -0.9275],\n",
      "        [ 0.8768,  0.0145, -0.1483,  0.7101, -0.6908,  0.1361],\n",
      "        ...,\n",
      "        [-0.8155,  0.2695,  0.0032, -0.3205,  0.9301, -0.1793],\n",
      "        [-0.7604,  0.1678,  0.1526, -0.8972, -0.1857,  0.4007],\n",
      "        [-0.8403,  0.2445, -0.0152, -0.9430,  0.3155,  0.1055]])\n",
      "tensor([[1.1074, 0.1018, 1.2133,  ..., 0.6742, 1.3744, 1.0898],\n",
      "        [0.8857, 0.1143, 1.1985,  ..., 1.2117, 1.3744, 1.0531],\n",
      "        [1.0356, 0.1516, 0.6496,  ..., 1.6172, 2.4451, 3.7761],\n",
      "        ...,\n",
      "        [0.1432, 0.2407, 1.5333,  ..., 0.6164, 3.0104, 0.3801],\n",
      "        [0.0089, 0.1163, 1.9122,  ..., 1.1152, 0.4290, 6.7573],\n",
      "        [1.0388, 0.1344, 2.1152,  ..., 2.7802, 2.8356, 1.1152]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0507e-03,  9.3395e-01, -2.3948e-01,  ...,  1.2039e+00,\n",
      "          9.5637e-01,  9.8130e-01],\n",
      "        [ 6.8416e-04,  4.7123e-01,  6.4168e-01,  ...,  1.2788e+00,\n",
      "          6.4957e-01,  1.2133e+00],\n",
      "        [ 8.2866e-04,  8.2893e-01, -2.8351e-02,  ...,  1.0598e+00,\n",
      "          8.8329e-01,  1.1985e+00],\n",
      "        ...,\n",
      "        [ 5.4633e-04, -8.4814e-01, -2.6610e-02,  ...,  3.4314e-01,\n",
      "          4.4895e-01,  2.3495e+00],\n",
      "        [ 8.2483e-04, -7.8405e-01, -3.1211e-02,  ...,  2.0943e+00,\n",
      "          3.9105e-01,  6.5624e-01],\n",
      "        [ 2.7544e-03, -9.1332e-01, -2.5247e-01,  ...,  5.9722e-01,\n",
      "          1.9122e+00,  6.3221e-01]], dtype=torch.float64)\n",
      "tensor(indices=tensor([[  0,   0,   0,  ..., 251, 251, 251],\n",
      "                       [  1,   2,   3,  ..., 248, 249, 250]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(252, 252), nnz=1500, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[  0,   0,   0,  ..., 749, 749, 749],\n",
      "                       [  1,   2,   5,  ..., 742, 746, 748]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(750, 750), nnz=3000, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[  0,   0,   0,  ..., 499, 499, 499],\n",
      "                       [  1,   2,   5,  ..., 491, 494, 498]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(500, 500), nnz=1500, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[  0,   0,   0,  ..., 251, 251, 251],\n",
      "                       [  0,   1,   2,  ..., 742, 748, 749]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(252, 750), nnz=1500, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[  0,   0,   1,  ..., 748, 749, 749],\n",
      "                       [  0,   1,   0,  ..., 499, 494, 499]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(750, 500), nnz=1500, layout=torch.sparse_coo)\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_test_list[i_cc].shape}.\")\n",
    "print(f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_test_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_test_list[i_cc].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:12:40.935701Z",
     "start_time": "2023-06-29T09:12:40.933077Z"
    }
   },
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:11.069615Z",
     "start_time": "2023-06-29T10:21:11.060143Z"
    }
   },
   "outputs": [],
   "source": [
    "d_0 = training_node_feat[0].shape[-1]\n",
    "d_1 = training_edge_feat[0].shape[-1]\n",
    "d_2 = training_face_feat[0].shape[-1]\n",
    "\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T08:28:51.149986Z",
     "start_time": "2023-06-29T08:28:51.144331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8690, -0.0219, -0.0431,  0.5085,  0.6664, -0.5453],\n",
      "        [ 0.9026, -0.0730,  0.0168,  0.9621,  0.0354,  0.2704],\n",
      "        [ 0.8901, -0.0837, -0.0672,  0.7793,  0.2262, -0.5844],\n",
      "        ...,\n",
      "        [-0.8531, -0.0409,  0.1088, -0.9241, -0.1282,  0.3600],\n",
      "        [-0.8517,  0.0935, -0.0554, -0.9194,  0.3311, -0.2122],\n",
      "        [-0.8742,  0.0140,  0.0262, -0.9966,  0.0628,  0.0539]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.layer = HMCLayer(\n",
    "            in_channels=in_channels,\n",
    "            intermediate_channels=intermediate_channels,\n",
    "            out_channels=out_channels,\n",
    "            negative_slope=negative_slope,\n",
    "        )\n",
    "        \"\"\"self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope\n",
    "            ) for _ in range(n_layers)\n",
    "        )\"\"\"\n",
    "\n",
    "        self.l0 = torch.nn.Linear(out_channels[0], num_classes)\n",
    "        self.l1 = torch.nn.Linear(out_channels[1], num_classes)\n",
    "        self.l2 = torch.nn.Linear(out_channels[2], num_classes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        x_0, x_1, x_2 = self.layer(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            neighborhood_0_to_0,\n",
    "            neighborhood_1_to_1,\n",
    "            neighborhood_2_to_2,\n",
    "            neighborhood_0_to_1,\n",
    "            neighborhood_1_to_2,\n",
    "        )\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2\n",
    "                                  )\"\"\"\n",
    "\n",
    "        x_0 = self.l0(x_0)\n",
    "        x_1 = self.l1(x_1)\n",
    "        x_2 = self.l2(x_2)\n",
    "\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:11.467775Z",
     "start_time": "2023-06-29T10:21:11.463344Z"
    }
   },
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:11.833724Z",
     "start_time": "2023-06-29T10:21:11.831231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5280, -0.5312,  0.0055, -0.9404, -0.2801,  0.1930],\n",
      "        [-0.4962, -0.5500, -0.0275, -0.2368, -0.7371, -0.6329],\n",
      "        [-0.4748, -0.5537,  0.0069,  0.2126, -0.9430,  0.2561],\n",
      "        ...,\n",
      "        [ 0.7673,  0.4709,  0.0332,  0.5263,  0.7800,  0.3387],\n",
      "        [ 0.7886,  0.4498, -0.0085,  0.9372,  0.3407, -0.0749],\n",
      "        [ 0.7647,  0.4704, -0.0378,  0.4602,  0.7919, -0.4014]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.unique(training_labels).shape[0]\n",
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=num_classes,\n",
    "    n_layers=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:23.697609Z",
     "start_time": "2023-06-28T15:38:23.505866Z"
    }
   },
   "source": [
    "We train the HoanMeshClassifier using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:49.313610Z",
     "start_time": "2023-06-29T10:21:12.935718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 loss: 654795.3756 Train_acc: 0.0250\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_63000/3112448459.py\", line 38, in <module>\n",
      "    y_hat = model.forward(\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_63000/4123705235.py\", line 58, in forward\n",
      "    x_0, x_1, x_2 = layer(x_0,\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/manuellecha/PycharmProjects/TopoModelX_UBTeam/topomodelx/nn/combinatorial/hmc_layer.py\", line 175, in forward\n",
      "    )\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/manuellecha/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py\", line 196, in forward\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/torch/_tensor.py\", line 1259, in to_sparse_coo\n",
      "    return self.to_sparse()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "test_interval = 25\n",
    "num_epochs = 500\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for (\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        adjacency_0,\n",
    "        adjacency_1,\n",
    "        coadjacency_2,\n",
    "        incidence_1,\n",
    "        incidence_2,\n",
    "        y,\n",
    "    ) in zip(\n",
    "        training_node_feat,\n",
    "        training_edge_feat,\n",
    "        training_face_feat,\n",
    "        adjacency_0_train_list,\n",
    "        adjacency_1_train_list,\n",
    "        coadjacency_2_train_list,\n",
    "        incidence_1_train_list,\n",
    "        incidence_2_train_list,\n",
    "        training_labels,\n",
    "    ):\n",
    "        x_0, x_1, x_2 = (\n",
    "            torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "        )\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "            adjacency_0.float().to(device),\n",
    "            adjacency_1.float().to(device),\n",
    "            coadjacency_2.float().to(device),\n",
    "        )\n",
    "        incidence_1, incidence_2 = incidence_1.float().to(\n",
    "            device\n",
    "        ), incidence_2.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model.forward(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            adjacency_0,\n",
    "            adjacency_1,\n",
    "            coadjacency_2,\n",
    "            incidence_1,\n",
    "            incidence_2,\n",
    "        )\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2, y in zip(\n",
    "                testing_node_feat, testing_edge_feat, testing_face_feat, adjacency_0_test_list, adjacency_1_test_list, coadjacency_2_test_list, incidence_1_test_list, incidence_2_test_list, testing_labels\n",
    "            ):\n",
    "                x_0, x_1, x_2 = (\n",
    "                    torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "                )\n",
    "                y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "                adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "                    adjacency_0.float().to(device),\n",
    "                    adjacency_1.float().to(device),\n",
    "                    coadjacency_2.float().to(device),\n",
    "                )\n",
    "                incidence_1, incidence_2 = incidence_1.float().to(\n",
    "                    device\n",
    "                ), incidence_2.float().to(device)\n",
    "                opt.zero_grad()\n",
    "                y_hat = model.forward(x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2)\n",
    "                loss = crit(y_hat, y)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:42:24.147446Z",
     "start_time": "2023-06-29T09:42:24.145570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
