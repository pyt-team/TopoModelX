{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Combinatorial Complex Attention Neural Network for Mesh Classification.\n",
    "\n",
    "We create and train a combinatorial complex attention neural network for mesh classification, introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The neural network is composed of a sequence of identical attention layers for a dimension two combinatorial complex. Each layer is composed of two levels. In both levels, messages computed for the cells of identical dimension are aggregated using a sum operation. All the messages are computed using the attention mechanisms for squared and non-squared neighborhoods presented in [Definitions 31, 32, and 33, Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). The following message passing scheme is followed in each of the levels for each layer:\n",
    "\n",
    "1. First level:\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) h_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 0}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad  m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) h_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 1}\\right) h_y^{t,(2)} \\Theta^t_{2\\rightarrow 1}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 0}_{x}=\\sum_{y\\in B_{1}(x)} m^{1\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 1}_{x}=\\sum_{y\\in B_{2}(x)} m^{2\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{0\\rightarrow 1}_{x}+m^{2\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad i_x^{t,(2)} = m_x^{(2)}$\n",
    "\n",
    "where $i_x^{t,(\\cdot)}$ represents intermediate feature vectors.\n",
    "\n",
    "\n",
    "2. Second level:\n",
    "\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 0}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 0})_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 0}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 0}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\uparrow, 1})_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 1}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{2\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((A_{\\downarrow, 2})_{xy} \\cdot \\text{att}_{xy}^{2\\rightarrow 2}\\right) i_y^{t,(2)} \\Theta^t_{2\\rightarrow 2}\\right)$\n",
    "\n",
    "游린 $\\quad m^{0\\rightarrow 1}_{y\\rightarrow x} = \\phi\\left(\\left((B_{1}^T)_{xy} \\cdot \\text{att}_{xy}^{0\\rightarrow 1}\\right) i_y^{t,(0)} \\Theta^t_{0\\rightarrow 1}\\right)$\n",
    "\n",
    "游린 $\\quad m^{1\\rightarrow 2}_{y\\rightarrow x} = \\phi\\left(\\left((B_{2}^T)_{xy} \\cdot \\text{att}_{xy}^{1\\rightarrow 2}\\right) i_y^{t,(1)} \\Theta^t_{1\\rightarrow 2}\\right)$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 0}_{x}=\\sum_{y\\in A_{\\uparrow, 0}(x)} m^{0\\rightarrow 0}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 1}_{x}=\\sum_{y\\in A_{\\uparrow, 1}(x)} m^{1\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{2\\rightarrow 2}_{x}=\\sum_{y\\in A_{\\downarrow, 2}(x)} m^{2\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{0\\rightarrow 1}_{x}=\\sum_{y\\in B_{1}^T(x)} m^{0\\rightarrow 1}_{y\\rightarrow x}$\n",
    "\n",
    "游릲 $\\quad m^{1\\rightarrow 2}_{x}=\\sum_{y\\in B_{2}^T(x)} m^{1\\rightarrow 2}_{y\\rightarrow x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(0)}=m^{0\\rightarrow 0}_{x}+m^{1\\rightarrow 0}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(1)}=m^{1\\rightarrow 1}_{x} + m^{0\\rightarrow 1}_{x}$\n",
    "\n",
    "游릴 $\\quad m_x^{(2)}=m^{1\\rightarrow 2}_{x} + m^{2\\rightarrow 2}_{x}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = m_x^{(0)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(1)} = m_x^{(1)}$\n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(2)} = m_x^{(2)}$\n",
    "\n",
    "In both message passing levels, $\\phi$ represents a common activation function. Also, $\\Theta$ and $\\text{att}$ represent learnable weights and attention matrices, respectively, that are different in each level. Attention matrices are introduced in [Figure 35(b), Hajij et. al : Topological Deep Learning: Going Beyond Graph Data (2023)](https://arxiv.org/pdf/2206.00606.pdf). In this case, attention matrices are computed using the LeakyReLU activation function, as in previous versions of the paper.\n",
    "\n",
    "Notations, adjacency, coadjacency, and incidence matrices are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031). The tensor diagram for the layer can be found in the first column and last row of Figure 11, from the same paper.\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:51:48.023871Z",
     "start_time": "2023-07-03T07:51:48.022537Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:51:49.016509Z",
     "start_time": "2023-07-03T07:51:49.013407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:51:55.668089Z",
     "start_time": "2023-07-03T07:51:55.657152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading shrec 16 full dataset...\n",
      "\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "shrec_training, shrec_testing = shrec_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:56:29.185827Z",
     "start_time": "2023-07-03T07:56:29.182349Z"
    }
   },
   "outputs": [],
   "source": [
    "class SHRECDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.complexes = [cc.to_combinatorial_complex() for cc in data[\"complexes\"]]\n",
    "        self.x_0 = data[\"node_feat\"]\n",
    "        self.x_1 = data[\"edge_feat\"]\n",
    "        self.x_2 = data[\"face_feat\"]\n",
    "        self.y = data[\"label\"]\n",
    "        self.a0, self.a1, self.coa2, self.b1, self.b2 = self._get_neighborhood_matrix()\n",
    "\n",
    "    def _get_neighborhood_matrix(self):\n",
    "\n",
    "        a0 = []\n",
    "        a1 = []\n",
    "        coa2 = []\n",
    "        b1 = []\n",
    "        b2 = []\n",
    "\n",
    "        for cc in self.complexes:\n",
    "\n",
    "            a0.append(torch.from_numpy(cc.adjacency_matrix(0, 1).todense()).to_sparse())\n",
    "            a1.append(torch.from_numpy(cc.adjacency_matrix(1, 2).todense()).to_sparse())\n",
    "\n",
    "            B = cc.incidence_matrix(rank=2, to_rank=1)\n",
    "            A = B.T @ B\n",
    "            A.setdiag(0)\n",
    "            coa2.append(torch.from_numpy(A.todense()).to_sparse())\n",
    "\n",
    "            b1.append(torch.from_numpy(cc.incidence_matrix(1, 0).todense()).to_sparse())\n",
    "            b2.append(torch.from_numpy(cc.incidence_matrix(2, 1).todense()).to_sparse())\n",
    "\n",
    "        return a0, a1, coa2, b1, b2\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(np.unique(self.y))\n",
    "\n",
    "    def channels_dim(self):\n",
    "        return self.x_0[0].shape[1], self.x_1[0].shape[1], self.x_2[0].shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.complexes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x_0[idx],\n",
    "            self.x_1[idx],\n",
    "            self.x_2[idx],\n",
    "            self.a0[idx],\n",
    "            self.a1[idx],\n",
    "            self.coa2[idx],\n",
    "            self.b1[idx],\n",
    "            self.b2[idx],\n",
    "            self.y[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:57:55.252993Z",
     "start_time": "2023-07-03T07:56:29.398492Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dataset = SHRECDataset(shrec_training)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:59:12.380996Z",
     "start_time": "2023-07-03T07:57:55.226774Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_dataset = SHRECDataset(shrec_training)\n",
    "testing_dataloader = DataLoader(training_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T09:12:40.935701Z",
     "start_time": "2023-06-29T09:12:40.933077Z"
    }
   },
   "source": [
    "# Create the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:59:12.383383Z",
     "start_time": "2023-07-03T07:59:12.380156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 7.\n"
     ]
    }
   ],
   "source": [
    "d_0, d_1, d_2 = training_dataset.channels_dim()\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T07:59:12.391146Z",
     "start_time": "2023-07-03T07:59:12.389211Z"
    }
   },
   "outputs": [],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "        final_layer_embedding_dimension=20,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope,\n",
    "                softmax_attention=True,\n",
    "                update_func_attention=\"relu\",\n",
    "                update_func_aggregation=\"relu\",\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        )\n",
    "        self.l0 = torch.nn.Linear(out_channels[0], final_layer_embedding_dimension)\n",
    "        self.l1 = torch.nn.Linear(out_channels[1], final_layer_embedding_dimension)\n",
    "        self.l2 = torch.nn.Linear(out_channels[2], final_layer_embedding_dimension)\n",
    "        self.final_layer = torch.nn.Linear(\n",
    "            3 * final_layer_embedding_dimension, num_classes\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2,\n",
    "            )\n",
    "        \"\"\"\n",
    "        # Take the sum of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nansum(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "\n",
    "        x_0 = self.l0(zero_dimensional_cells_mean)\n",
    "        x_1 = self.l1(one_dimensional_cells_mean)\n",
    "        x_2 = self.l2(two_dimensional_cells_mean)\n",
    "\n",
    "\n",
    "        #return F.softmax(x_0 + x_1 + x_2, dim=-1)\n",
    "        return x_0 + x_1 + x_2\n",
    "        \"\"\"\n",
    "        x_0 = self.l0(x_0)\n",
    "        x_1 = self.l1(x_1)\n",
    "        x_2 = self.l2(x_2)\n",
    "        # Sum all the elements in the dimension zero\n",
    "        x_0 = torch.nanmean(x_0, dim=0)\n",
    "        x_1 = torch.nanmean(x_1, dim=0)\n",
    "        x_2 = torch.nanmean(x_2, dim=0)\n",
    "        x = torch.cat((x_0, x_1, x_2), dim=0)\n",
    "        return self.final_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T10:21:11.467775Z",
     "start_time": "2023-06-29T10:21:11.463344Z"
    }
   },
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T08:03:56.225449Z",
     "start_time": "2023-07-03T08:03:56.218834Z"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_channels = [100, 100, 100]\n",
    "final_channels = [100, 100, 100]\n",
    "\n",
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    intermediate_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=training_dataset.num_classes(),\n",
    "    n_layers=1,\n",
    "    final_layer_embedding_dimension=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:39:23.697609Z",
     "start_time": "2023-06-28T15:38:23.505866Z"
    }
   },
   "source": [
    "We train the HoanMeshClassifier using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, model, training_dataloader, testing_dataloader, learning_rate, device\n",
    "    ):\n",
    "        \"\"\"Initializes the trainer with model, dataloaders, learning rate, and device.\"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.training_dataloader = training_dataloader\n",
    "        self.testing_dataloader = testing_dataloader\n",
    "        self.device = device\n",
    "        self.crit = torch.nn.CrossEntropyLoss()\n",
    "        self.opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    def _to_device(self, x):\n",
    "        \"\"\"Converts tensors to the correct type and moves them to the device.\"\"\"\n",
    "        return [el[0].float().to(self.device) for el in x]\n",
    "\n",
    "    def train(self, num_epochs=500, test_interval=25):\n",
    "        \"\"\"Trains the model for the specified number of epochs.\"\"\"\n",
    "        for epoch_i in range(num_epochs):\n",
    "            training_accuracy, epoch_loss = self._train_epoch()\n",
    "            print(\n",
    "                f\"Epoch: {epoch_i} loss: {epoch_loss:.4f} Train_acc: {training_accuracy:.4f}\",\n",
    "                flush=True,\n",
    "            )\n",
    "            if (epoch_i + 1) % test_interval == 0:\n",
    "                test_accuracy = self.validate()\n",
    "                print(f\"Test_acc: {test_accuracy:.4f}\", flush=True)\n",
    "\n",
    "    def _train_epoch(self):\n",
    "        \"\"\"Trains the model for one epoch.\"\"\"\n",
    "        training_samples = len(self.training_dataloader.dataset)\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        self.model.train()\n",
    "        for sample in self.training_dataloader:\n",
    "            (\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                adjacency_0,\n",
    "                adjacency_1,\n",
    "                coadjacency_2,\n",
    "                incidence_1,\n",
    "                incidence_2,\n",
    "            ) = self._to_device(sample[:-1])\n",
    "\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            y_hat = self.model.forward(\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                adjacency_0,\n",
    "                adjacency_1,\n",
    "                coadjacency_2,\n",
    "                incidence_1,\n",
    "                incidence_2,\n",
    "            )\n",
    "\n",
    "            y = sample[-1][0].long().to(self.device)\n",
    "            total_loss += self._compute_loss_and_update(y_hat, y)\n",
    "            correct += (y_hat.argmax() == y).sum().item()\n",
    "\n",
    "        training_accuracy = correct / training_samples\n",
    "        epoch_loss = total_loss / training_samples\n",
    "\n",
    "        return training_accuracy, epoch_loss\n",
    "\n",
    "    def _compute_loss_and_update(self, y_hat, y):\n",
    "        \"\"\"Computes the loss, performs backpropagation, and updates the model's parameters.\"\"\"\n",
    "        loss = self.crit(y_hat, y)\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Validates the model using the testing dataloader.\"\"\"\n",
    "        correct = 0\n",
    "        self.model.eval()\n",
    "        test_samples = len(self.testing_dataloader.dataset)\n",
    "        with torch.no_grad():\n",
    "            for sample in self.testing_dataloader:\n",
    "                (\n",
    "                    x_0,\n",
    "                    x_1,\n",
    "                    x_2,\n",
    "                    adjacency_0,\n",
    "                    adjacency_1,\n",
    "                    coadjacency_2,\n",
    "                    incidence_1,\n",
    "                    incidence_2,\n",
    "                ) = self._to_device(sample[:-1])\n",
    "\n",
    "                y_hat = self.model(\n",
    "                    x_0,\n",
    "                    x_1,\n",
    "                    x_2,\n",
    "                    adjacency_0,\n",
    "                    adjacency_1,\n",
    "                    coadjacency_2,\n",
    "                    incidence_1,\n",
    "                    incidence_2,\n",
    "                )\n",
    "                y = sample[-1][0].long().to(self.device)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "            test_accuracy = correct / test_samples\n",
    "            return test_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T08:26:21.751218Z",
     "start_time": "2023-07-03T08:26:21.747575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "trainer = Trainer(model, training_dataloader, testing_dataloader, 0.001, \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T08:26:22.248769Z",
     "start_time": "2023-07-03T08:26:22.245803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 loss: 1.4025 Train_acc: 0.5229\n",
      "Epoch: 1 loss: 1.2714 Train_acc: 0.5583\n",
      "Epoch: 2 loss: 1.2041 Train_acc: 0.5708\n",
      "Epoch: 3 loss: 1.1085 Train_acc: 0.6188\n",
      "Epoch: 4 loss: 0.9987 Train_acc: 0.6500\n",
      "Epoch: 5 loss: 0.9877 Train_acc: 0.6604\n",
      "Epoch: 6 loss: 0.9208 Train_acc: 0.6854\n",
      "Epoch: 7 loss: 0.8291 Train_acc: 0.7146\n",
      "Epoch: 8 loss: 0.8049 Train_acc: 0.7042\n",
      "Epoch: 9 loss: 0.7337 Train_acc: 0.7500\n",
      "Epoch: 10 loss: 0.7134 Train_acc: 0.7375\n",
      "Epoch: 11 loss: 0.6624 Train_acc: 0.7729\n",
      "Epoch: 12 loss: 0.6511 Train_acc: 0.7771\n",
      "Epoch: 13 loss: 0.5759 Train_acc: 0.7958\n",
      "Epoch: 14 loss: 0.6288 Train_acc: 0.7729\n",
      "Epoch: 15 loss: 0.5740 Train_acc: 0.7917\n",
      "Epoch: 16 loss: 0.5556 Train_acc: 0.7854\n",
      "Epoch: 17 loss: 0.5091 Train_acc: 0.7958\n",
      "Epoch: 18 loss: 0.4983 Train_acc: 0.8208\n",
      "Epoch: 19 loss: 0.4640 Train_acc: 0.8333\n",
      "Epoch: 20 loss: 0.4449 Train_acc: 0.8500\n",
      "Epoch: 21 loss: 0.5013 Train_acc: 0.8167\n",
      "Epoch: 22 loss: 0.4369 Train_acc: 0.8438\n",
      "Epoch: 23 loss: 0.4487 Train_acc: 0.8250\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_90025/49973641.py\", line 1, in <module>\n",
      "    trainer.train()\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_90025/12018842.py\", line 20, in train\n",
      "    training_accuracy, epoch_loss = self._train_epoch()\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_90025/12018842.py\", line 61, in _train_epoch\n",
      "    total_loss += self._compute_loss_and_update(y_hat, y)\n",
      "  File \"/var/folders/ll/bd2dgg_50_52khsw_lrcpvwc0000gn/T/ipykernel_90025/12018842.py\", line 72, in _compute_loss_and_update\n",
      "    loss.backward()\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    retain_graph=retain_graph,\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 978, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 878, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 712, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/manuellecha/miniconda3/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T08:29:54.689714Z",
     "start_time": "2023-07-03T08:26:22.631492Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
