{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Convolutional Cell Complex Network (CCXN)\n",
    "\n",
    "We create and train a simplified version of the CCXN originally proposed in [Hajij et. al : Cell Complex Neural Networks (2020)](https://arxiv.org/pdf/2010.00743.pdf).\n",
    "\n",
    "### The Neural Network:\n",
    "\n",
    "The equations of one layer of this neural network are given by:\n",
    "\n",
    "1. A convolution from nodes to nodes using an adjacency message passing scheme (AMPS):\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow \\{z\\} \\rightarrow x}^{(0 \\rightarrow 1 \\rightarrow 0)} = M_{\\mathcal{L}_\\uparrow}^t(h_x^{t,(0)}, h_y^{t,(0)}, \\Theta^{t,(y \\rightarrow x)})$ \n",
    "\n",
    "游릲 $\\quad m_x^{(0 \\rightarrow 1 \\rightarrow 0)} = AGG_{y \\in \\mathcal{L}_\\uparrow(x)}(m_{y \\rightarrow \\{z\\} \\rightarrow x}^{0 \\rightarrow 1 \\rightarrow 0})$ \n",
    "\n",
    "游릴 $\\quad m_x^{(0)} = m_x^{(0 \\rightarrow 1 \\rightarrow 0)}$ \n",
    "\n",
    "游릱 $\\quad h_x^{t+1,(0)} = U^{t}(h_x^{t,(0)}, m_x^{(0)})$\n",
    "\n",
    "2. A convolution from edges to faces using a cohomology message passing scheme:\n",
    "\n",
    "游린 $\\quad m_{y \\rightarrow x}^{(r' \\rightarrow r)} = M^t_{\\mathcal{C}}(h_{x}^{t,(r)}, h_y^{t,(r')}, x, y)$ \n",
    "\n",
    "游릲 $\\quad m_x^{(r' \\rightarrow r)}  = AGG_{y \\in \\mathcal{C}(x)} m_{y \\rightarrow x}^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릴 $\\quad m_x^{(r)} = m_x^{(r' \\rightarrow r)}$ \n",
    "\n",
    "游릱 $\\quad h_{x}^{t+1,(r)} = U^{t,(r)}(h_{x}^{t,(r)}, m_{x}^{(r)})$\n",
    "\n",
    "Where the notations are defined in [Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)](https://arxiv.org/abs/2304.10031).\n",
    "\n",
    "### The Task:\n",
    "\n",
    "We train this model to perform entire complex classification on [`MUTAG` from the TUDataset](https://paperswithcode.com/dataset/mutag). This dataset contains:\n",
    "- 188 samples of chemical compounds represented as graphs,\n",
    "- with 7 discrete node features.\n",
    "\n",
    "The task is to predict the mutagenicity of each compound on Salmonella typhimurium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T17:20:18.198625Z",
     "start_time": "2023-06-15T17:20:18.192724Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from toponetx import CombinatorialComplex\n",
    "from toponetx.datasets.mesh import shrec_16\n",
    "from sklearn.model_selection import train_test_split\n",
    "from topomodelx.nn.combinatorial.hmc_layer import HMCLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPU's are available, we will make use of them. Otherwise, this will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-15T17:20:19.296861Z",
     "start_time": "2023-06-15T17:20:19.293614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing\n",
    "\n",
    "## Import data ##\n",
    "\n",
    "We import a subset of MUTAG, a benchmark dataset for graph classification.\n",
    "\n",
    "We then lift each graph into our topological domain of choice, here: a cell complex.\n",
    "\n",
    "We also retrieve:\n",
    "- input signals `x_0` and `x_1` on the nodes (0-cells) and edges (1-cells) for each complex: these will be the model's inputs,\n",
    "- a binary classification label `y` associated to the cell complex."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping the files...\n",
      "\n",
      "done!\n",
      "Loading dataset...\n",
      "\n",
      "done!\n",
      "<class 'toponetx.classes.simplicial_complex.SimplicialComplex'>\n"
     ]
    }
   ],
   "source": [
    "shrec_training, shrec_testing = shrec_16()\n",
    "\n",
    "# training dataset\n",
    "training_complexes = [\n",
    "    cc.to_combinatorial_complex() for cc in shrec_training[\"complexes\"]\n",
    "]\n",
    "training_labels = shrec_training[\"label\"]\n",
    "training_node_feat = shrec_training[\"node_feat\"]\n",
    "training_edge_feat = shrec_training[\"edge_feat\"]\n",
    "training_face_feat = shrec_training[\"face_feat\"]\n",
    "\n",
    "# testing dataset\n",
    "testing_complexes = [cc.to_combinatorial_complex() for cc in shrec_testing[\"complexes\"]]\n",
    "testing_labels = shrec_testing[\"label\"]\n",
    "testing_node_feat = shrec_testing[\"node_feat\"]\n",
    "testing_edge_feat = shrec_testing[\"edge_feat\"]\n",
    "testing_face_feat = shrec_testing[\"face_feat\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:22:39.278276Z",
     "start_time": "2023-06-22T13:21:26.987816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CombinatorialComplex.skeleton() got an unexpected keyword argument 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_complexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincidence_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mto_rank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidence_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtodense()\n",
      "File \u001b[0;32m~/PycharmProjects/TopoNetX/toponetx/classes/combinatorial_complex.py:1041\u001b[0m, in \u001b[0;36mCombinatorialComplex.incidence_matrix\u001b[0;34m(self, rank, to_rank, incidence_type, weight, sparse, index)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mincidence_matrix\u001b[39m(\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28mself\u001b[39m, rank, to_rank, incidence_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute incidence matrix for the CC indexed by nodes x cells.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m        Dictionary identifying columns with cells\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_incidence_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidence_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincidence_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/TopoNetX/toponetx/classes/combinatorial_complex.py:259\u001b[0m, in \u001b[0;36mCombinatorialComplex._incidence_matrix\u001b[0;34m(self, rank, to_rank, incidence_type, weight, sparse, index)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m incidence_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    258\u001b[0m         uidset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskeleton(rank)\n\u001b[0;32m--> 259\u001b[0m         children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskeleton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlower\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TopoNetXError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincidence_type must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: CombinatorialComplex.skeleton() got an unexpected keyword argument 'level'"
     ]
    }
   ],
   "source": [
    "training_complexes[0].incidence_matrix(\n",
    "    rank=2, to_rank=None, incidence_type=\"down\"\n",
    ").todense()\n",
    "# what is going on with self.skeleton??"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:25:54.250695Z",
     "start_time": "2023-06-22T13:25:54.210555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.567542  ,  0.570995  , -0.210023  , -0.06894332,  0.72564355,\n         0.6846081 ],\n       [ 0.603908  ,  0.557968  , -0.223298  ,  0.91155493,  0.37192256,\n         0.17533174],\n       [ 0.591494  ,  0.464737  ,  0.350567  ,  0.33390166,  0.55019138,\n         0.76537515],\n       ...,\n       [-0.331773  , -0.33001   ,  0.049767  , -0.28529544, -0.95405566,\n        -0.09156586],\n       [-0.401883  , -0.263047  ,  0.136766  , -0.66302596, -0.62547973,\n         0.41130485],\n       [ 0.261249  ,  0.128185  ,  0.304997  ,  0.7728916 , -0.44845904,\n         0.44891321]])"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Node features:\n",
    "    - Position\n",
    "    - Normal\n",
    "\"\"\"\n",
    "\n",
    "training_node_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:11:01.320392Z",
     "start_time": "2023-06-22T13:11:01.317382Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.22957341, 0.13581241, 0.45991269, ..., 2.25198965, 2.89552337,\n        2.00058261],\n       [1.43636325, 0.14296384, 0.58913082, ..., 1.74326848, 2.89552337,\n        0.51764337],\n       [0.96944867, 0.11326229, 0.70546737, ..., 2.4000534 , 2.25383585,\n        0.468195  ],\n       ...,\n       [0.39824646, 0.12369258, 0.55931499, ..., 0.945035  , 0.59602236,\n        4.14184985],\n       [0.19510851, 0.11228415, 1.07026534, ..., 3.67055053, 2.41476323,\n        0.51704672],\n       [0.0621548 , 0.122271  , 1.95575932, ..., 2.90562928, 1.5314299 ,\n        0.66267758]])"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Edge features:\n",
    "    - Dihedral angle\n",
    "    - Edge span\n",
    "    - 2 edge angle in the triangle\n",
    "    - 6 edge ratios\n",
    "\"\"\"\n",
    "\n",
    "training_edge_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:11:01.323628Z",
     "start_time": "2023-06-22T13:11:01.320623Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 6.16026555e-04,  3.42332662e-01,  9.39444198e-01, ...,\n         9.55859971e-01,  4.28478956e-01,  1.75725373e+00],\n       [ 6.81088138e-04,  3.97494225e-01,  1.96188417e-01, ...,\n         4.59912686e-01,  1.33996485e+00,  1.34171512e+00],\n       [ 2.02495554e-03, -7.65949901e-01,  4.13444548e-01, ...,\n         1.32871011e+00,  1.22375172e+00,  5.89130819e-01],\n       ...,\n       [ 1.88118714e-03,  1.16577970e-01, -9.84528932e-01, ...,\n         3.64363423e-01,  1.93855641e+00,  8.38672818e-01],\n       [ 1.50431667e-03, -4.34561991e-01, -8.48251445e-01, ...,\n         1.54860901e+00,  5.77114229e-01,  1.01586942e+00],\n       [ 1.74908308e-03, -8.97968600e-01, -3.36066581e-01, ...,\n         1.04615878e+00,  1.50159627e+00,  5.93837603e-01]])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Face features:\n",
    "    - Face area\n",
    "    - Face normal\n",
    "    - Face angle\n",
    "\"\"\"\n",
    "\n",
    "training_face_feat[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:11:01.328475Z",
     "start_time": "2023-06-22T13:11:01.326350Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# training_complexes[0].to_trimesh().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T17:21:19.288044Z",
     "start_time": "2023-06-15T17:21:19.285789Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:37:06.801153Z",
     "start_time": "2023-06-09T15:37:06.796903Z"
    }
   },
   "source": [
    "## Define neighborhood structures. ##\n",
    "\n",
    "Implementing the CCXN architecture will require to perform message passing along neighborhood structures of the cell complexes.\n",
    "\n",
    "Thus, now we retrieve these neighborhood structures (i.e. their representative matrices) that we will use to send messages. \n",
    "\n",
    "For the CCXN, we need the adjacency matrix $A_{\\uparrow, 0}$ and the coboundary matrix $B_2^T$ of each cell complex."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0, 1, 1, ..., 0, 0, 0],\n        [1, 0, 1, ..., 0, 0, 0],\n        [1, 1, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 1],\n        [0, 0, 0, ..., 0, 1, 0]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T13:12:39.886432Z",
     "start_time": "2023-06-22T13:11:28.752481Z"
    }
   },
   "outputs": [],
   "source": [
    "adjacency_0_train_list = []\n",
    "adjacency_1_train_list = []\n",
    "coadjacency_2_train_list = []\n",
    "\n",
    "incidence_1_train_list = []\n",
    "incidence_2_train_list = []\n",
    "\n",
    "for cc in training_complexes:\n",
    "\n",
    "    adjacency_0_train = torch.from_numpy(\n",
    "        cc.adjacency_matrix(0, 1).todense()\n",
    "    ).to_sparse()\n",
    "    adjacency_1_train = torch.from_numpy(\n",
    "        cc.adjacency_matrix(1, 2).todense()\n",
    "    ).to_sparse()\n",
    "    coadjacency_2_train = torch.from_numpy(\n",
    "        cc.coadjacency_matrix(2, 1).todense()\n",
    "    ).to_sparse()\n",
    "\n",
    "    adjacency_0_train_list.append(adjacency_0_train)\n",
    "    adjacency_1_train_list.append(adjacency_1_train)\n",
    "    coadjacency_2_train_list.append(coadjacency_2_train)\n",
    "\n",
    "    incidence_1_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(1, 0).todense()\n",
    "    ).to_sparse()\n",
    "    incidence_2_train = torch.from_numpy(\n",
    "        cc.incidence_matrix(2, 1).todense()\n",
    "    ).to_sparse()\n",
    "\n",
    "    incidence_1_train_list.append(incidence_1_train)\n",
    "    incidence_2_train_list.append(incidence_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CombinatorialComplex.skeleton() got an unexpected keyword argument 'level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#training_complexes[0].coadjacency_matrix(rank=2,via_rank=1).todense()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[0;32m----> 3\u001b[0m B \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_complexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincidence_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mto_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mincidence_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdown\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(B\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m A \u001b[38;5;241m=\u001b[39m csr_matrix(B\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m@\u001b[39m csr_matrix(B)\n",
      "File \u001b[0;32m~/PycharmProjects/TopoNetX/toponetx/classes/combinatorial_complex.py:1041\u001b[0m, in \u001b[0;36mCombinatorialComplex.incidence_matrix\u001b[0;34m(self, rank, to_rank, incidence_type, weight, sparse, index)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mincidence_matrix\u001b[39m(\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28mself\u001b[39m, rank, to_rank, incidence_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute incidence matrix for the CC indexed by nodes x cells.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m        Dictionary identifying columns with cells\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_incidence_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidence_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincidence_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/TopoNetX/toponetx/classes/combinatorial_complex.py:259\u001b[0m, in \u001b[0;36mCombinatorialComplex._incidence_matrix\u001b[0;34m(self, rank, to_rank, incidence_type, weight, sparse, index)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m incidence_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    258\u001b[0m         uidset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskeleton(rank)\n\u001b[0;32m--> 259\u001b[0m         children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskeleton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlower\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TopoNetXError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincidence_type must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: CombinatorialComplex.skeleton() got an unexpected keyword argument 'level'"
     ]
    }
   ],
   "source": [
    "# training_complexes[0].coadjacency_matrix(rank=2,via_rank=1).todense()\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "B = training_complexes[0].incidence_matrix(\n",
    "    rank=2, to_rank=None, incidence_type=\"down\", sparse=True\n",
    ")\n",
    "print(B.shape)\n",
    "A = csr_matrix(B.T) @ csr_matrix(B)\n",
    "print(A.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-22T13:17:58.588600Z",
     "start_time": "2023-06-22T13:17:58.545968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Adjacency_1 of the 0-th complex: torch.Size([750, 750]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n"
     ]
    }
   ],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_train_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_train_list[i_cc].shape}.\")\n",
    "print(\n",
    "    f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_train_list[i_cc].shape}.\"\n",
    ")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_train_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_train_list[i_cc].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-16T09:16:39.293163Z",
     "start_time": "2023-06-16T09:16:39.288228Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "adjacency_0_test_list = []\n",
    "adjacency_1_test_list = []\n",
    "coadjacency_2_test_list = []\n",
    "incidence_1_test_list = []\n",
    "incidence_2_test_list = []\n",
    "\n",
    "for cc in testing_complexes:\n",
    "\n",
    "    adjacency_0_test = torch.from_numpy(cc.adjacency_matrix(0, 1).todense()).to_sparse()\n",
    "    adjacency_1_test = torch.from_numpy(cc.adjacency_matrix(1, 2).todense()).to_sparse()\n",
    "    coadjacency_2_test = torch.from_numpy(\n",
    "        cc.coadjacency_matrix(2, 1).todense()\n",
    "    ).to_sparse()\n",
    "\n",
    "    adjacency_0_test_list.append(adjacency_0_test)\n",
    "    adjacency_1_test_list.append(adjacency_1_test)\n",
    "    coadjacency_2_test_list.append(coadjacency_2_test)\n",
    "\n",
    "    incidence_1_test = torch.from_numpy(cc.incidence_matrix(1, 0).todense()).to_sparse()\n",
    "    incidence_2_test = torch.from_numpy(cc.incidence_matrix(2, 1).todense()).to_sparse()\n",
    "\n",
    "    incidence_1_test_list.append(incidence_1_test)\n",
    "    incidence_2_test_list.append(incidence_2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T17:22:50.633215Z",
     "start_time": "2023-06-15T17:22:32.559733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency_0 of the 0-th complex: torch.Size([252, 252]).\n",
      "Coadjacency_2 of the 0-th complex: torch.Size([750, 750]).\n",
      "Adjacency_1 of the 0-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 0-th complex: torch.Size([252, 750]).\n",
      "Incidence_2 of the 0-th complex: torch.Size([750, 500]).\n"
     ]
    }
   ],
   "source": [
    "i_cc = 0\n",
    "print(f\"Adjacency_0 of the {i_cc}-th complex: {adjacency_0_test_list[i_cc].shape}.\")\n",
    "print(f\"Coadjacency_2 of the {i_cc}-th complex: {coadjacency_2_test_list[i_cc].shape}.\")\n",
    "print(f\"Adjacency_1 of the {i_cc}-th complex: {adjacency_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_1 of the {i_cc}-th complex: {incidence_1_test_list[i_cc].shape}.\")\n",
    "print(f\"Incidence_2 of the {i_cc}-th complex: {incidence_2_test_list[i_cc].shape}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T17:22:50.637333Z",
     "start_time": "2023-06-15T17:22:50.635296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:47:58.549790Z",
     "start_time": "2023-06-09T15:47:58.546827Z"
    }
   },
   "source": [
    "# Create the Neural Network\n",
    "\n",
    "Using the CCXNLayer class, we create a neural network with stacked layers."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency of the 1-th complex: torch.Size([252, 252]).\n",
      "Coadjacency of the 1-th complex: torch.Size([750, 750]).\n",
      "Incidence_1 of the 1-th complex: torch.Size([252, 750]).\n",
      "Incidence_1_t of the 1-th complex: torch.Size([750, 252]).\n",
      "Incidence_2 of the 1-th complex: torch.Size([750, 500]).\n",
      "Incidence_2_t of the 1-th complex: torch.Size([500, 750]).\n",
      "torch.Size([750, 500]) torch.Size([500, 750])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T09:10:39.794775Z",
     "start_time": "2023-06-16T09:10:39.778076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of input features on nodes, edges and faces are: 6, 10 and 7.\n"
     ]
    }
   ],
   "source": [
    "d_0 = training_node_feat[0].shape[-1]\n",
    "d_1 = training_edge_feat[0].shape[-1]\n",
    "d_2 = training_face_feat[0].shape[-1]\n",
    "\n",
    "in_channels = [d_0, d_1, d_2]\n",
    "\n",
    "print(\n",
    "    f\"The dimension of input features on nodes, edges and faces are: {d_0}, {d_1} and {d_2}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T09:10:42.003050Z",
     "start_time": "2023-06-16T09:10:41.997859Z"
    }
   },
   "outputs": [],
   "source": [
    "class HoanMeshClassifier(torch.nn.Module):\n",
    "    \"\"\"HoanMeshClassifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : List[int]\n",
    "        Dimension of input features on nodes, edges and faces respectively.\n",
    "    intermediate_channels : List[int]\n",
    "        Dimension of intermediate features on nodes, edges and faces respectively.\n",
    "    out_channels : List[int]\n",
    "        Dimension of output features on nodes, edges and faces respectively.\n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "    n_layers : int\n",
    "        Number of CCXN layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        intermediate_channels,\n",
    "        out_channels,\n",
    "        num_classes,\n",
    "        negative_slope=0.2,\n",
    "        n_layers=1,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.layer = HMCLayer(\n",
    "            in_channels=in_channels,\n",
    "            intermediate_channels=intermediate_channels,\n",
    "            out_channels=out_channels,\n",
    "            negative_slope=negative_slope,\n",
    "        )\n",
    "        \"\"\"self.layers = torch.nn.ModuleList(\n",
    "            HMCLayer(\n",
    "                in_channels=in_channels,\n",
    "                intermediate_channels=intermediate_channels,\n",
    "                out_channels=out_channels,\n",
    "                negative_slope=negative_slope\n",
    "            ) for _ in range(n_layers)\n",
    "        )\"\"\"\n",
    "\n",
    "        self.l0 = torch.nn.Linear(out_channels[0], num_classes)\n",
    "        self.l1 = torch.nn.Linear(out_channels[1], num_classes)\n",
    "        self.l2 = torch.nn.Linear(out_channels[2], num_classes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        neighborhood_0_to_0,\n",
    "        neighborhood_1_to_1,\n",
    "        neighborhood_2_to_2,\n",
    "        neighborhood_0_to_1,\n",
    "        neighborhood_1_to_2,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        x_0, x_1, x_2 = self.layer(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            neighborhood_0_to_0,\n",
    "            neighborhood_1_to_1,\n",
    "            neighborhood_2_to_2,\n",
    "            neighborhood_0_to_1,\n",
    "            neighborhood_1_to_2,\n",
    "        )\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x_0, x_1, x_2 = layer(x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                neighborhood_0_to_0,\n",
    "                neighborhood_1_to_1,\n",
    "                neighborhood_2_to_2,\n",
    "                neighborhood_0_to_1,\n",
    "                neighborhood_1_to_2\n",
    "                                  )\"\"\"\n",
    "\n",
    "        x_0 = self.l0(x_0)\n",
    "        x_1 = self.l1(x_1)\n",
    "        x_2 = self.l2(x_2)\n",
    "\n",
    "        # Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.\n",
    "        two_dimensional_cells_mean = torch.nanmean(x_2, dim=0)\n",
    "        two_dimensional_cells_mean[torch.isnan(two_dimensional_cells_mean)] = 0\n",
    "        one_dimensional_cells_mean = torch.nanmean(x_1, dim=0)\n",
    "        one_dimensional_cells_mean[torch.isnan(one_dimensional_cells_mean)] = 0\n",
    "        zero_dimensional_cells_mean = torch.nanmean(x_0, dim=0)\n",
    "        zero_dimensional_cells_mean[torch.isnan(zero_dimensional_cells_mean)] = 0\n",
    "        # Return the sum of the averages\n",
    "        return (\n",
    "            two_dimensional_cells_mean\n",
    "            + one_dimensional_cells_mean\n",
    "            + zero_dimensional_cells_mean\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "We specify the model, initialize loss, and specify an optimizer. We first try it without any attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T09:10:43.121683Z",
     "start_time": "2023-06-16T09:10:43.114077Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = np.unique(training_labels).shape[0]\n",
    "model = HoanMeshClassifier(\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    in_channels,\n",
    "    negative_slope=0.2,\n",
    "    num_classes=num_classes,\n",
    "    n_layers=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "crit = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the HoanMeshClassifier using low amount of epochs: we keep training minimal for the purpose of rapid testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T09:10:48.549043Z",
     "start_time": "2023-06-16T09:10:48.424155Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (750x750 and 500x500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m incidence_1, incidence_2 \u001b[38;5;241m=\u001b[39m incidence_1\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device), incidence_2\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoadjacency_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidence_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincidence_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m crit(y_hat, y)\n\u001b[1;32m     18\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (y_hat\u001b[38;5;241m.\u001b[39margmax() \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[57], line 61\u001b[0m, in \u001b[0;36mHoanMeshClassifier.forward\u001b[0;34m(self, x_0, x_1, x_2, neighborhood_0_to_0, neighborhood_1_to_1, neighborhood_2_to_2, neighborhood_0_to_1, neighborhood_1_to_2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m         x_0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m         neighborhood_1_to_2,\n\u001b[1;32m     59\u001b[0m         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 61\u001b[0m     x_0, x_1, x_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneighborhood_0_to_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneighborhood_1_to_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneighborhood_2_to_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneighborhood_0_to_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mneighborhood_1_to_2\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    for layer in self.layers:\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m        x_0, x_1, x_2 = layer(x_0,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m            neighborhood_1_to_2\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m                              )\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     x_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml0(x_0)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/nn/combinatorial/hmc_layer.py:84\u001b[0m, in \u001b[0;36mHMCLayer.forward\u001b[0;34m(self, x_0, x_1, x_2, adjacency_0, adjacency_1, coadjacency_2, incidence_1, incidence_2)\u001b[0m\n\u001b[1;32m     82\u001b[0m x_0_to_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhbs_0_level2(x_0_level1, adjacency_0)\n\u001b[1;32m     83\u001b[0m x_1_to_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhbs_1_level2(x_1_level1, adjacency_1)\n\u001b[0;32m---> 84\u001b[0m x_2_to_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhbs_2_level2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_2_level1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoadjacency_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m _, x_0_to_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhbns_0_1_level2(x_0_level1, x_1_level1, incidence_1)\n\u001b[1;32m     86\u001b[0m _, x_1_to_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhbns_1_2_level2(x_1_level1, x_2_level1, incidence_2)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:122\u001b[0m, in \u001b[0;36mHBS.forward\u001b[0;34m(self, x_source, neighborhood)\u001b[0m\n\u001b[1;32m    120\u001b[0m message \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mmm(x_source, w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight]  \u001b[38;5;66;03m# [m-hop, n_source_cells, d_t_out]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(x_source\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto_sparse_coo()\n\u001b[0;32m--> 122\u001b[0m neighborhood \u001b[38;5;241m=\u001b[39m [result \u001b[38;5;241m:=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mmm(neighborhood, result) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_hop)]\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# TODO: parallelize?\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# with Pool() as pool:\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# att_p = pool.map(self.attention, message)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m att \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(m_p, A_p, a_p) \u001b[38;5;28;01mfor\u001b[39;00m m_p, A_p, a_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(message, neighborhood, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_weight)]\n",
      "File \u001b[0;32m~/PycharmProjects/TopoModelX_UBTeam/topomodelx/base/hbs.py:122\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m message \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mmm(x_source, w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight]  \u001b[38;5;66;03m# [m-hop, n_source_cells, d_t_out]\u001b[39;00m\n\u001b[1;32m    121\u001b[0m result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(x_source\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto_sparse_coo()\n\u001b[0;32m--> 122\u001b[0m neighborhood \u001b[38;5;241m=\u001b[39m [result \u001b[38;5;241m:=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighborhood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_hop)]\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# TODO: parallelize?\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# with Pool() as pool:\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# att_p = pool.map(self.attention, message)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m att \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(m_p, A_p, a_p) \u001b[38;5;28;01mfor\u001b[39;00m m_p, A_p, a_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(message, neighborhood, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_weight)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (750x750 and 500x500)"
     ]
    }
   ],
   "source": [
    "test_interval = 2\n",
    "num_epochs = 4\n",
    "for epoch_i in range(1, num_epochs + 1):\n",
    "    epoch_loss = []\n",
    "    num_samples = 0\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    for (\n",
    "        x_0,\n",
    "        x_1,\n",
    "        x_2,\n",
    "        adjacency_0,\n",
    "        adjacency_1,\n",
    "        coadjacency_2,\n",
    "        incidence_1,\n",
    "        incidence_2,\n",
    "        y,\n",
    "    ) in zip(\n",
    "        training_node_feat,\n",
    "        training_edge_feat,\n",
    "        training_face_feat,\n",
    "        adjacency_0_train_list,\n",
    "        adjacency_1_train_list,\n",
    "        coadjacency_2_train_list,\n",
    "        incidence_1_train_list,\n",
    "        incidence_2_train_list,\n",
    "        training_labels,\n",
    "    ):\n",
    "        x_0, x_1, x_2 = (\n",
    "            torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "            torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "        )\n",
    "        y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "        adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "            adjacency_0.float().to(device),\n",
    "            adjacency_1.float().to(device),\n",
    "            coadjacency_2.float().to(device),\n",
    "        )\n",
    "        incidence_1, incidence_2 = incidence_1.float().to(\n",
    "            device\n",
    "        ), incidence_2.float().to(device)\n",
    "        opt.zero_grad()\n",
    "        y_hat = model.forward(\n",
    "            x_0,\n",
    "            x_1,\n",
    "            x_2,\n",
    "            adjacency_0,\n",
    "            adjacency_1,\n",
    "            coadjacency_2,\n",
    "            incidence_1,\n",
    "            incidence_2,\n",
    "        )\n",
    "        loss = crit(y_hat, y)\n",
    "        correct += (y_hat.argmax() == y).sum().item()\n",
    "        num_samples += 1\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    train_acc = correct / num_samples\n",
    "    print(\n",
    "        f\"Epoch: {epoch_i} loss: {np.mean(epoch_loss):.4f} Train_acc: {train_acc:.4f}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    if epoch_i % test_interval == 0:\n",
    "        with torch.no_grad():\n",
    "            num_samples = 0\n",
    "            correct = 0\n",
    "            for (\n",
    "                x_0,\n",
    "                x_1,\n",
    "                x_2,\n",
    "                adjacency_0,\n",
    "                adjacency_1,\n",
    "                coadjacency_2,\n",
    "                incidence_1,\n",
    "                incidence_2,\n",
    "                y,\n",
    "            ) in zip(\n",
    "                testing_node_feat,\n",
    "                testing_edge_feat,\n",
    "                testing_face_feat,\n",
    "                adjacency_0_test_list,\n",
    "                adjacency_1_test_list,\n",
    "                coadjacency_2_train_list,\n",
    "                incidence_1_train_list,\n",
    "                incidence_2_train_list,\n",
    "                testing_labels,\n",
    "            ):\n",
    "                x_0, x_1, x_2 = (\n",
    "                    torch.tensor(x_0, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_1, dtype=torch.float).to(device),\n",
    "                    torch.tensor(x_2, dtype=torch.float).to(device),\n",
    "                )\n",
    "                y = torch.tensor(y, dtype=torch.long).to(device)\n",
    "                adjacency_0, adjacency_1, coadjacency_2 = (\n",
    "                    adjacency_0.float().to(device),\n",
    "                    adjacency_1.float().to(device),\n",
    "                    coadjacency_2.float().to(device),\n",
    "                )\n",
    "                incidence_1, incidence_2 = incidence_1.float().to(\n",
    "                    device\n",
    "                ), incidence_2.float().to(device)\n",
    "                opt.zero_grad()\n",
    "                y_hat = model(\n",
    "                    x_0,\n",
    "                    x_1,\n",
    "                    x_2,\n",
    "                    adjacency_0,\n",
    "                    adjacency_1,\n",
    "                    coadjacency_2,\n",
    "                    incidence_1,\n",
    "                    incidence_2,\n",
    "                )\n",
    "                loss = crit(y_hat, y)\n",
    "                correct += (y_hat.argmax() == y).sum().item()\n",
    "                num_samples += 1\n",
    "            test_acc = correct / num_samples\n",
    "            print(f\"Test_acc: {test_acc:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3., 4., 5.])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3, 4, 5]).float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T14:40:44.741439Z",
     "start_time": "2023-06-15T14:40:44.737078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "a = [3, 5, 6]\n",
    "a.float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T14:37:48.603974Z",
     "start_time": "2023-06-15T14:37:48.586184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "hmc = HMCLayer([3, 3, 3], [3, 3, 3], [3, 3, 3], negative_slope=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T16:00:40.457458Z",
     "start_time": "2023-06-15T16:00:40.452852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
